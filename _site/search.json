[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tony Tech Blog",
    "section": "",
    "text": "Weather Forecast App with Streamlit and AI Integration\n\n\n\nTony D\n\n\nNov 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nInteractive GDP Trend Dashboard with AI SQL\n\n\n\n\n\n\nNov 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeight Tracking Dashboard with Shiny,streamlit and AI Integration\n\n\n\nTony D\n\n\nNov 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhisky Tasting note with RAG\n\n\n\nTony D\n\n\nNov 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nYOLO Object Detection App with Streamlit\n\n\n\nTony D\n\n\nNov 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nRetrieval-Augmented Generation(RAG) in R & Python\n\n\n\nTony D\n\n\nNov 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpenRouter: A Unified API for Multiple AI Models\n\n\n\nTony D\n\n\nNov 1, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/yolo-app/index.html",
    "href": "posts/yolo-app/index.html",
    "title": "YOLO Object Detection App with Streamlit",
    "section": "",
    "text": "The application is a comprehensive Streamlit web app that provides object detection capabilities using YOLO11 (Ultralytics framework) with support for multiple input sources and processing backends. What makes this project special is its multi-model architecture and production-ready features.\nLive Demo: https://yolo-live.streamlit.app/\nGithub: https://github.com/JCwinning/YOLO_app\n\n\n\nApplication Screenshot - Main Interface\n\n\n\n\n\nApplication Screenshot - Detection Results\n\n\n\n\n\n\nThe application supports various input methods: - File Upload: Images and videos from local storage - URL Input: Direct image URLs from the web - Live Camera: Real-time photo capture using device cameras\n\n\n\nOne of the standout features is the support for different AI models:\n\n\n\nFive different model variants (nano, small, medium, large, extra-large)\nAutomatic device detection with MPS acceleration for Apple Silicon\nCPU fallback for broader compatibility\n\n\n\n\n\nQwen-Image-Edit via DashScope API for advanced image annotation\nGemini 2.5 Flash Image via OpenRouter API for cutting-edge processing\n\n\n\n\n\n\nBilingual Interface: Full English/Chinese support with 113+ translated strings\nSmart UI Management: Automatic hiding of input images after processing\nDownload Capabilities: Save annotated results locally\nProgress Tracking: Real-time progress updates for video processing\nSession Management: Persistent state across user interactions\n\n\n\n\n\n\n\n\n\n\n\n\n System Architecture Diagram \n\n\n\n\n\n[project]\nname = \"yolo-app\"\nrequires-python = \"&gt;=3.12\"\ndependencies = [\n    \"dashscope&gt;=1.17.0\",      # Alibaba Cloud API\n    \"opencv-python&gt;=4.11.0.86\", # Computer vision\n    \"streamlit&gt;=1.50.0\",       # Web framework\n    \"torch&gt;=2.2\",              # Deep learning\n    \"ultralytics&gt;=8.3.0\",      # YOLO framework\n]\n\n\n\nThe main application (app.py) consists of over 1,000 lines of well-structured Python code organized into several key components:\n\n\nfrom language import translations\n\ndef get_translation(key, **kwargs):\n    \"\"\"Translation function that uses the current session language\"\"\"\n    lang = st.session_state.get(\"language\", \"en\")\n    text = translations[lang].get(key, translations[\"en\"].get(key, key))\n    return text.format(**kwargs) if kwargs else text\n\n\n\ndef get_device():\n    \"\"\"Automatically detect the best available device\"\"\"\n    if torch.backends.mps.is_available():\n        return \"mps\"  # Apple Silicon GPU acceleration\n    return \"cpu\"      # Fallback to CPU\n\n# Model loading with device optimization\ndevice = get_device()\nmodel = YOLO(selected_model).to(device)\nst.info(f\"Using device: {device.upper()}\")\n\n\n\ndef encode_image_to_base64(image):\n    \"\"\"Encode PIL Image to base64 string with size compression\"\"\"\n    max_size_bytes = 8 * 1024 * 1024  # 8MB limit\n\n    formats_and_qualities = [\n        (\"JPEG\", 95), (\"JPEG\", 85), (\"JPEG\", 75),\n        (\"WEBP\", 95), (\"WEBP\", 85), (\"WEBP\", 75),\n    ]\n\n    for fmt, quality in formats_and_qualities:\n        # Try different compression strategies\n        # ... compression logic\n\n\n\n\n\n\nThe app supports all YOLO11 model variants with automatic performance optimization:\n# Model selection interface\nmodel_options = [\"yolo11n.pt\", \"yolo11s.pt\", \"yolo11m.pt\", \"yolo11l.pt\", \"yolo11x.pt\"]\nmodel_descriptions = {\n    \"yolo11n.pt\": \"Nano - Fastest, lowest accuracy\",\n    \"yolo11s.pt\": \"Small - Good balance\",\n    \"yolo11m.pt\": \"Medium - Recommended\",\n    \"yolo11l.pt\": \"Large - Higher accuracy\",\n    \"yolo11x.pt\": \"Extra Large - Highest accuracy\"\n}\n\nselected_model = st.sidebar.selectbox(\n    get_translation(\"model_selection\"),\n    model_options,\n    index=model_options.index(\"yolo11s.pt\"),\n    format_func=lambda x: f\"{model_descriptions[x]} ({x})\"\n)\n\n# Detection process with progress tracking\ndef detect_objects(image, model, confidence_threshold=0.5):\n    \"\"\"Perform object detection with progress tracking\"\"\"\n    with st.spinner(get_translation(\"processing\")):\n        results = model.predict(image, conf=confidence_threshold)\n\n        # Process results\n        detections = []\n        for result in results:\n            boxes = result.boxes\n            for box in boxes:\n                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n                conf = box.conf[0].cpu().numpy()\n                cls = int(box.cls[0].cpu().numpy())\n                class_name = model.names[cls]\n\n                detections.append({\n                    'class': class_name,\n                    'confidence': conf,\n                    'bbox': [x1, y1, x2, y2]\n                })\n\n    return detections, results\n\n\n\nFor cloud-based models, the app handles API authentication and request formatting:\ndef process_with_qwen(image, api_key):\n    \"\"\"Process image using Qwen-Image-Edit via DashScope\"\"\"\n    try:\n        response = MultiModalConversation.call(\n            model='qwen-image-edit',\n            input=[\n                {\n                    'role': 'user',\n                    'content': [\n                        {'image': f\"data:image/jpeg;base64,{image_b64}\"},\n                        {'text': 'Please identify and label all objects in this image.'}\n                    ]\n                }\n            ]\n        )\n        return response\n    except Exception as e:\n        st.error(f\"API Error: {str(e)}\")\n        return None\n\n\n\n\n\n\n\nThe application uses a professional three-column layout:\n\nSidebar: Model selection, confidence threshold, language settings\nMain Area: Input method selection, image/video display, results\nResults Panel: Detection statistics, download options\n\n\n\n\nThe translation system handles all UI elements:\ntranslations = {\n    \"en\": {\n        \"title\": \"YOLO11 Object Detection\",\n        \"upload_file\": \"Upload File\",\n        \"camera_input\": \"Use Camera\",\n        # ... more strings\n    },\n    \"zh\": {\n        \"title\": \"YOLO11 ÁõÆÊ†áÊ£ÄÊµã\",\n        \"upload_file\": \"‰∏ä‰º†Êñá‰ª∂\",\n        \"camera_input\": \"‰ΩøÁî®Áõ∏Êú∫\",\n        # ... corresponding translations\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nParameters\nmAP\nInference Time (CPU)\nInference Time (MPS)\n\n\n\n\nYOLO11n\n2.6M\n37.2\n15ms\n3ms\n\n\nYOLO11s\n9.4M\n45.5\n28ms\n6ms\n\n\nYOLO11m\n25.4M\n51.2\n52ms\n12ms\n\n\nYOLO11l\n43.7M\n53.4\n84ms\n18ms\n\n\nYOLO11x\n68.2M\n54.7\n126ms\n26ms\n\n\n\n\n\n\nThe app automatically detects and utilizes Metal Performance Shaders (MPS) on Apple Silicon devices:\ndevice = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\nmodel = YOLO(selected_model).to(device)\n\n# Performance monitoring\nimport time\nstart_time = time.time()\nresults = model.predict(image)\ninference_time = (time.time() - start_time) * 1000\n\nst.metric(f\"Inference Time ({device.upper()})\", f\"{inference_time:.1f}ms\")\n\n\n\nTo meet API size limits, the app implements smart image compression:\ndef compress_image_for_api(image, max_size=8*1024*1024):\n    \"\"\"Compress image to meet API requirements\"\"\"\n    for quality in [95, 85, 75, 65]:\n        for fmt in [\"JPEG\", \"WEBP\"]:\n            buffer = BytesIO()\n            image.save(buffer, format=fmt, quality=quality)\n            if buffer.tell() &lt;= max_size:\n                return buffer.getvalue()\n    return None\n\n\n\n\n\n\nThe application maintains comprehensive session state:\nsession_state_vars = [\n    \"current_image\", \"uploaded_image_bytes\",\n    \"current_video\", \"uploaded_video_bytes\",\n    \"camera_active\", \"camera_frame\",\n    \"qwen_processed\", \"gemini_processed\",\n    \"language\", \"input_method_index\"\n]\n\n\n\nRobust error handling ensures graceful degradation:\ntry:\n    result = model.predict(image, conf=confidence_threshold)\n    st.success(get_translation(\"detection_success\"))\nexcept Exception as e:\n    st.error(f\"Detection failed: {str(e)}\")\n    # Fallback to alternative processing method\n\n\n\n\nThe application is deployed and accessible at: https://yolo-live.streamlit.app/\n\n\n\n\n\n\nPython 3.12 or higher\nModern package manager (uv recommended)\nFor cloud models: API keys from DashScope and OpenRouter\n\n\n\n\n# Clone the repository\ngit clone &lt;repository-url&gt;\ncd YOLO_app\n\n# Install dependencies with uv (recommended)\nuv sync\n\n# Alternative: pip install\npip install -r requirements.txt\n\n# Run the application\nstreamlit run app.py\n\n\n\nCreate a .env file with your API keys:\n# Alibaba Cloud DashScope API\nDASHSCOPE_API_KEY=your_dashscope_key\n\n# OpenRouter API (for Gemini)\nOPENROUTER_API_KEY=your_openrouter_key\n\n\n\n\n\n\nLaunch the application\nUpload an image or provide an image URL\nSelect your preferred YOLO11 model (yolo11s.pt recommended)\nAdjust confidence threshold if needed\nClick ‚ÄúDetect Objects‚Äù\nView results and download annotated image\n\n\n\n\n\nSelect ‚ÄúUse Camera‚Äù input method\nGrant camera permissions when prompted\nCapture a photo\nChoose detection model\nGet instant object detection results\n\n\n\n\n\nEnter your API keys in the sidebar\nUpload an image\nSelect ‚ÄúQwen-Image-Edit‚Äù or ‚ÄúGemini 2.5 Flash‚Äù model\nProcess image with advanced AI capabilities\nCompare results with local YOLO models\n\n\n\n\n\n\nPotential improvements for future versions:\n\nAdditional Models: Integration with more cloud AI services\nReal-time Video Processing: Enhanced video streaming capabilities\nCustom Model Training: Allow users to train custom YOLO models\nMobile Optimization: PWA features for mobile device support\nBatch Processing: Process multiple images simultaneously\n\n\n\n\nThis YOLO object detection application demonstrates how to build a sophisticated, production-ready computer vision system. The combination of local and cloud-based models, bilingual support, and comprehensive error handling makes it suitable for both development and production environments.\nThe project showcases best practices in: - Modern Python development with dependency management - Streamlit web application architecture - Computer vision API integration - Internationalization and accessibility - Performance optimization for different hardware platforms\nWhether you‚Äôre interested in computer vision, web development, or AI applications, this project provides an excellent foundation for building advanced AI-powered web applications.\n\nGitHub Repository: YOLO_app Live Demo: https://yolo-live.streamlit.app/ Dependencies: Full requirements.txt"
  },
  {
    "objectID": "posts/yolo-app/index.html#key-features",
    "href": "posts/yolo-app/index.html#key-features",
    "title": "YOLO Object Detection App with Streamlit",
    "section": "",
    "text": "The application supports various input methods: - File Upload: Images and videos from local storage - URL Input: Direct image URLs from the web - Live Camera: Real-time photo capture using device cameras\n\n\n\nOne of the standout features is the support for different AI models:\n\n\n\nFive different model variants (nano, small, medium, large, extra-large)\nAutomatic device detection with MPS acceleration for Apple Silicon\nCPU fallback for broader compatibility\n\n\n\n\n\nQwen-Image-Edit via DashScope API for advanced image annotation\nGemini 2.5 Flash Image via OpenRouter API for cutting-edge processing\n\n\n\n\n\n\nBilingual Interface: Full English/Chinese support with 113+ translated strings\nSmart UI Management: Automatic hiding of input images after processing\nDownload Capabilities: Save annotated results locally\nProgress Tracking: Real-time progress updates for video processing\nSession Management: Persistent state across user interactions"
  },
  {
    "objectID": "posts/yolo-app/index.html#technical-architecture",
    "href": "posts/yolo-app/index.html#technical-architecture",
    "title": "YOLO Object Detection App with Streamlit",
    "section": "",
    "text": "System Architecture Diagram \n\n\n\n\n\n[project]\nname = \"yolo-app\"\nrequires-python = \"&gt;=3.12\"\ndependencies = [\n    \"dashscope&gt;=1.17.0\",      # Alibaba Cloud API\n    \"opencv-python&gt;=4.11.0.86\", # Computer vision\n    \"streamlit&gt;=1.50.0\",       # Web framework\n    \"torch&gt;=2.2\",              # Deep learning\n    \"ultralytics&gt;=8.3.0\",      # YOLO framework\n]\n\n\n\nThe main application (app.py) consists of over 1,000 lines of well-structured Python code organized into several key components:\n\n\nfrom language import translations\n\ndef get_translation(key, **kwargs):\n    \"\"\"Translation function that uses the current session language\"\"\"\n    lang = st.session_state.get(\"language\", \"en\")\n    text = translations[lang].get(key, translations[\"en\"].get(key, key))\n    return text.format(**kwargs) if kwargs else text\n\n\n\ndef get_device():\n    \"\"\"Automatically detect the best available device\"\"\"\n    if torch.backends.mps.is_available():\n        return \"mps\"  # Apple Silicon GPU acceleration\n    return \"cpu\"      # Fallback to CPU\n\n# Model loading with device optimization\ndevice = get_device()\nmodel = YOLO(selected_model).to(device)\nst.info(f\"Using device: {device.upper()}\")\n\n\n\ndef encode_image_to_base64(image):\n    \"\"\"Encode PIL Image to base64 string with size compression\"\"\"\n    max_size_bytes = 8 * 1024 * 1024  # 8MB limit\n\n    formats_and_qualities = [\n        (\"JPEG\", 95), (\"JPEG\", 85), (\"JPEG\", 75),\n        (\"WEBP\", 95), (\"WEBP\", 85), (\"WEBP\", 75),\n    ]\n\n    for fmt, quality in formats_and_qualities:\n        # Try different compression strategies\n        # ... compression logic\n\n\n\n\n\n\nThe app supports all YOLO11 model variants with automatic performance optimization:\n# Model selection interface\nmodel_options = [\"yolo11n.pt\", \"yolo11s.pt\", \"yolo11m.pt\", \"yolo11l.pt\", \"yolo11x.pt\"]\nmodel_descriptions = {\n    \"yolo11n.pt\": \"Nano - Fastest, lowest accuracy\",\n    \"yolo11s.pt\": \"Small - Good balance\",\n    \"yolo11m.pt\": \"Medium - Recommended\",\n    \"yolo11l.pt\": \"Large - Higher accuracy\",\n    \"yolo11x.pt\": \"Extra Large - Highest accuracy\"\n}\n\nselected_model = st.sidebar.selectbox(\n    get_translation(\"model_selection\"),\n    model_options,\n    index=model_options.index(\"yolo11s.pt\"),\n    format_func=lambda x: f\"{model_descriptions[x]} ({x})\"\n)\n\n# Detection process with progress tracking\ndef detect_objects(image, model, confidence_threshold=0.5):\n    \"\"\"Perform object detection with progress tracking\"\"\"\n    with st.spinner(get_translation(\"processing\")):\n        results = model.predict(image, conf=confidence_threshold)\n\n        # Process results\n        detections = []\n        for result in results:\n            boxes = result.boxes\n            for box in boxes:\n                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n                conf = box.conf[0].cpu().numpy()\n                cls = int(box.cls[0].cpu().numpy())\n                class_name = model.names[cls]\n\n                detections.append({\n                    'class': class_name,\n                    'confidence': conf,\n                    'bbox': [x1, y1, x2, y2]\n                })\n\n    return detections, results\n\n\n\nFor cloud-based models, the app handles API authentication and request formatting:\ndef process_with_qwen(image, api_key):\n    \"\"\"Process image using Qwen-Image-Edit via DashScope\"\"\"\n    try:\n        response = MultiModalConversation.call(\n            model='qwen-image-edit',\n            input=[\n                {\n                    'role': 'user',\n                    'content': [\n                        {'image': f\"data:image/jpeg;base64,{image_b64}\"},\n                        {'text': 'Please identify and label all objects in this image.'}\n                    ]\n                }\n            ]\n        )\n        return response\n    except Exception as e:\n        st.error(f\"API Error: {str(e)}\")\n        return None"
  },
  {
    "objectID": "posts/yolo-app/index.html#user-interface-design",
    "href": "posts/yolo-app/index.html#user-interface-design",
    "title": "YOLO Object Detection App with Streamlit",
    "section": "",
    "text": "The application uses a professional three-column layout:\n\nSidebar: Model selection, confidence threshold, language settings\nMain Area: Input method selection, image/video display, results\nResults Panel: Detection statistics, download options\n\n\n\n\nThe translation system handles all UI elements:\ntranslations = {\n    \"en\": {\n        \"title\": \"YOLO11 Object Detection\",\n        \"upload_file\": \"Upload File\",\n        \"camera_input\": \"Use Camera\",\n        # ... more strings\n    },\n    \"zh\": {\n        \"title\": \"YOLO11 ÁõÆÊ†áÊ£ÄÊµã\",\n        \"upload_file\": \"‰∏ä‰º†Êñá‰ª∂\",\n        \"camera_input\": \"‰ΩøÁî®Áõ∏Êú∫\",\n        # ... corresponding translations\n    }\n}"
  },
  {
    "objectID": "posts/yolo-app/index.html#performance-optimizations",
    "href": "posts/yolo-app/index.html#performance-optimizations",
    "title": "YOLO Object Detection App with Streamlit",
    "section": "",
    "text": "Model\nParameters\nmAP\nInference Time (CPU)\nInference Time (MPS)\n\n\n\n\nYOLO11n\n2.6M\n37.2\n15ms\n3ms\n\n\nYOLO11s\n9.4M\n45.5\n28ms\n6ms\n\n\nYOLO11m\n25.4M\n51.2\n52ms\n12ms\n\n\nYOLO11l\n43.7M\n53.4\n84ms\n18ms\n\n\nYOLO11x\n68.2M\n54.7\n126ms\n26ms\n\n\n\n\n\n\nThe app automatically detects and utilizes Metal Performance Shaders (MPS) on Apple Silicon devices:\ndevice = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\nmodel = YOLO(selected_model).to(device)\n\n# Performance monitoring\nimport time\nstart_time = time.time()\nresults = model.predict(image)\ninference_time = (time.time() - start_time) * 1000\n\nst.metric(f\"Inference Time ({device.upper()})\", f\"{inference_time:.1f}ms\")\n\n\n\nTo meet API size limits, the app implements smart image compression:\ndef compress_image_for_api(image, max_size=8*1024*1024):\n    \"\"\"Compress image to meet API requirements\"\"\"\n    for quality in [95, 85, 75, 65]:\n        for fmt in [\"JPEG\", \"WEBP\"]:\n            buffer = BytesIO()\n            image.save(buffer, format=fmt, quality=quality)\n            if buffer.tell() &lt;= max_size:\n                return buffer.getvalue()\n    return None"
  },
  {
    "objectID": "posts/yolo-app/index.html#deployment-and-production-features",
    "href": "posts/yolo-app/index.html#deployment-and-production-features",
    "title": "YOLO Object Detection App with Streamlit",
    "section": "",
    "text": "The application maintains comprehensive session state:\nsession_state_vars = [\n    \"current_image\", \"uploaded_image_bytes\",\n    \"current_video\", \"uploaded_video_bytes\",\n    \"camera_active\", \"camera_frame\",\n    \"qwen_processed\", \"gemini_processed\",\n    \"language\", \"input_method_index\"\n]\n\n\n\nRobust error handling ensures graceful degradation:\ntry:\n    result = model.predict(image, conf=confidence_threshold)\n    st.success(get_translation(\"detection_success\"))\nexcept Exception as e:\n    st.error(f\"Detection failed: {str(e)}\")\n    # Fallback to alternative processing method"
  },
  {
    "objectID": "posts/yolo-app/index.html#live-demo",
    "href": "posts/yolo-app/index.html#live-demo",
    "title": "YOLO Object Detection App with Streamlit",
    "section": "",
    "text": "The application is deployed and accessible at: https://yolo-live.streamlit.app/"
  },
  {
    "objectID": "posts/yolo-app/index.html#getting-started",
    "href": "posts/yolo-app/index.html#getting-started",
    "title": "YOLO Object Detection App with Streamlit",
    "section": "",
    "text": "Python 3.12 or higher\nModern package manager (uv recommended)\nFor cloud models: API keys from DashScope and OpenRouter\n\n\n\n\n# Clone the repository\ngit clone &lt;repository-url&gt;\ncd YOLO_app\n\n# Install dependencies with uv (recommended)\nuv sync\n\n# Alternative: pip install\npip install -r requirements.txt\n\n# Run the application\nstreamlit run app.py\n\n\n\nCreate a .env file with your API keys:\n# Alibaba Cloud DashScope API\nDASHSCOPE_API_KEY=your_dashscope_key\n\n# OpenRouter API (for Gemini)\nOPENROUTER_API_KEY=your_openrouter_key\n\n\n\n\n\n\nLaunch the application\nUpload an image or provide an image URL\nSelect your preferred YOLO11 model (yolo11s.pt recommended)\nAdjust confidence threshold if needed\nClick ‚ÄúDetect Objects‚Äù\nView results and download annotated image\n\n\n\n\n\nSelect ‚ÄúUse Camera‚Äù input method\nGrant camera permissions when prompted\nCapture a photo\nChoose detection model\nGet instant object detection results\n\n\n\n\n\nEnter your API keys in the sidebar\nUpload an image\nSelect ‚ÄúQwen-Image-Edit‚Äù or ‚ÄúGemini 2.5 Flash‚Äù model\nProcess image with advanced AI capabilities\nCompare results with local YOLO models"
  },
  {
    "objectID": "posts/yolo-app/index.html#future-enhancements",
    "href": "posts/yolo-app/index.html#future-enhancements",
    "title": "YOLO Object Detection App with Streamlit",
    "section": "",
    "text": "Potential improvements for future versions:\n\nAdditional Models: Integration with more cloud AI services\nReal-time Video Processing: Enhanced video streaming capabilities\nCustom Model Training: Allow users to train custom YOLO models\nMobile Optimization: PWA features for mobile device support\nBatch Processing: Process multiple images simultaneously"
  },
  {
    "objectID": "posts/yolo-app/index.html#conclusion",
    "href": "posts/yolo-app/index.html#conclusion",
    "title": "YOLO Object Detection App with Streamlit",
    "section": "",
    "text": "This YOLO object detection application demonstrates how to build a sophisticated, production-ready computer vision system. The combination of local and cloud-based models, bilingual support, and comprehensive error handling makes it suitable for both development and production environments.\nThe project showcases best practices in: - Modern Python development with dependency management - Streamlit web application architecture - Computer vision API integration - Internationalization and accessibility - Performance optimization for different hardware platforms\nWhether you‚Äôre interested in computer vision, web development, or AI applications, this project provides an excellent foundation for building advanced AI-powered web applications.\n\nGitHub Repository: YOLO_app Live Demo: https://yolo-live.streamlit.app/ Dependencies: Full requirements.txt"
  },
  {
    "objectID": "posts/whisky-tasting/index.html",
    "href": "posts/whisky-tasting/index.html",
    "title": "Whisky Tasting note with RAG",
    "section": "",
    "text": "The whisky tasting application is an advanced AI-powered web application that generates detailed, professional whisky tasting notes and recommendations. What makes this system special is its multi-agent architecture with specialized AI personalities, each trained on different whisky review sources and linguistic styles.\nLive Demo(modelscope): https://modelscope.cn/studios/ttflying/whisky_AI_tasting\nLive Demo(shinyapp): https://jcflyingco.shinyapps.io/ai-whisky-tasting/\nGithub: https://github.com/JCwinning/whisky_tasting\n\n\n\nApplication Interface - Agent Selection and Input\n\n\n\n\n\n\nThe application features three specialized AI agents, each with unique characteristics and data sources:\n\nDrunkTony (dt) - Chinese-language agent specializing in Chinese whisky reviews\nWhiskyFunny (wf) - English-language agent with data from whiskyfun.com\nWhiskyNotebook (wn) - English-language agent with data from whiskynotes.be\n\n\n\n\n\nPrimary Language: Python 3.13+\nWeb Framework: Streamlit (primary) + Shiny for Python (alternative)\nDatabase: DuckDB (376MB, optimized for vector operations)\nAI/ML: OpenAI API, Vector embeddings, RAG system\nData Sources: Web scraping with BeautifulSoup4\n\n\n\n\nAI Agent Configuration Panel\n\n\n\n\n\n\n\n\nThe system uses DuckDB as its primary database, chosen for its excellent performance with vector operations:\n-- Database structure\nCREATE TABLE drinktony_embed (\n    full TEXT,\n    bottle_embedding FLOAT[1024]  -- 1024-dimensional vectors\n);\n\nCREATE TABLE whiskyfun_embed (\n    full TEXT,\n    bottle_embedding FLOAT[1024]\n);\n\nCREATE TABLE whiskynote_embed (\n    full TEXT,\n    bottle_embedding FLOAT[1024]\n);\n\n\n\n# Web scraping example from get_data_dt.py\ndef scrape_drinktony_reviews():\n    \"\"\"Scrape Chinese whisky reviews from drinktony.netlify.app\"\"\"\n    url = \"https://drinktony.netlify.app/\"\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, \"html.parser\")\n\n    # Find all review links\n    post_links = [urljoin(url, a.get(\"href\"))\n                 for a in soup.select(\"a.quarto-grid-link\")]\n\n    all_reviews = []\n    for post_url in post_links:\n        response = requests.get(post_url)\n        soup = BeautifulSoup(response.content, \"html.parser\")\n\n        # Extract review sections\n        review_sections = soup.select(\"section.level1\")\n        for section in review_sections:\n            # Parse whisky name and review content\n            whisky_name = extract_whisky_name(section)\n            review_text = extract_review_text(section)\n            all_reviews.append({\n                'whisky': whisky_name,\n                'review': review_text\n            })\n\n    return all_reviews\n\n\n\n\n\n\nThe application uses state-of-the-art embedding technology to convert text into high-dimensional vectors for semantic similarity search.\n\n\nModel: BAAI/bge-large-zh-v1.5 - Dimensions: 1024 - Provider: SiliconFlow API - Purpose: Cross-lingual text understanding (works well for both Chinese and English)\n\n\n\n\nCross-lingual Capability: Excels at understanding both Chinese and English whisky terminology\nHigh Performance: Superior semantic understanding compared to generic embeddings\nEfficient Size: 1024 dimensions balance between performance and storage efficiency\nAPI Access: Stable service via SiliconFlow\n\n\n\n\nThe application uses BGE-Large-ZH-v1.5 model for generating embeddings:\ndef get_embedding(text: str, api_key: str):\n    \"\"\"Generate text embeddings using SiliconFlow API\"\"\"\n    client = OpenAI(\n        api_key=api_key,\n        base_url=\"https://api.siliconflow.cn/v1\"\n    )\n    response = client.embeddings.create(\n        model=\"BAAI/bge-large-zh-v1.5\",\n        input=[text]\n    )\n    return np.array(response.data[0].embedding)\n\ndef cosine_similarity(v1, v2):\n    \"\"\"Calculate cosine similarity between two vectors\"\"\"\n    if v1 is None or v2 is None:\n        return 0\n    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n\n\n\n\nThe Retrieval-Augmented Generation (RAG) system is the core innovation of this application. Let‚Äôs explore its components in detail.\n\n\n\nThe Retrieval-Augmented Generation process follows these steps:\n%%| fig-cap: \"RAG Workflow for Whisky Tasting\"\nflowchart TD\n    A[User Input&lt;br/&gt;Whisky Name] --&gt; B[Generate Embedding]\n    B --&gt; C[Vector Similarity Search&lt;br/&gt;in DuckDB]\n    C --&gt; D[Retrieve Top 10&lt;br/&gt;Similar Reviews]\n    D --&gt; E[Format Context for LLM]\n    E --&gt; F[Generate Tasting Notes&lt;br/&gt;with Primary LLM]\n    F --&gt; G[Generate Recommendations&lt;br/&gt;with Secondary LLM]\n    G --&gt; H[Display Results&lt;br/&gt;with Formatting]\n\n    C --&gt; I[Databases]\n    I --&gt; J[drinktony_embed&lt;br/&gt;1.2K Chinese reviews]\n    I --&gt; K[whiskyfun_embed&lt;br/&gt;20K English reviews]\n    I --&gt; L[whiskynote_embed&lt;br/&gt;5K English reviews]\n\n\n\ndef find_similar_chunks(\n    query_embedding,\n    db_path,\n    table_name,\n    text_col,\n    embedding_col,\n    top_n=10,\n):\n    \"\"\"Find most similar chunks in database using cosine similarity\"\"\"\n    try:\n        with duckdb.connect(database=db_path, read_only=True) as con:\n            df = con.execute(\n                f'SELECT \"{text_col}\", \"{embedding_col}\" FROM \"{table_name}\"'\n            ).fetchdf()\n\n            # Calculate similarities\n            similarities = []\n            for _, row in df.iterrows():\n                text = row[text_col]\n                embedding = np.array(row[embedding_col])\n                similarity = cosine_similarity(query_embedding, embedding)\n                similarities.append((text, similarity))\n\n            # Sort by similarity and return top N\n            similarities.sort(key=lambda x: x[1], reverse=True)\n            return similarities[:top_n]\n\n    except Exception as e:\n        print(f\"Error searching similar chunks: {e}\")\n        return []\n\n\n\n\n\n\ndef run_conversation(query, api_key, model):\n    \"\"\"Generate whisky tasting notes in Chinese format\"\"\"\n\n    # Step 1: Generate embedding and find similar reviews\n    query_embedding = get_embedding(query, api_key)\n    similar_reviews = find_similar_chunks(\n        query_embedding=query_embedding,\n        db_path=\"data/whisky_database.duckdb\",\n        table_name=\"drinktony_embed\",\n        text_col=\"full\",\n        embedding_col=\"bottle_embedding\"\n    )\n\n    # Step 2: Format context for LLM\n    context = \"\\n---\\n\".join([review[0] for review in similar_reviews])\n\n    # Step 3: Generate tasting notes\n    prompt = f\"\"\"‰Ωú‰∏∫Â®ÅÂ£´Âøå‰∏ìÂÆ∂ÔºåÂü∫‰∫é‰ª•‰∏ãÂ®ÅÂ£´ÂøåÂìÅÈâ¥Á¨îËÆ∞Ôºå‰∏∫\"{query}\"ÁîüÊàê‰∏ì‰∏öÁöÑÂìÅÈâ¥Êä•ÂëäÔºö\n\nÂèÇËÄÉÂìÅÈâ¥Á¨îËÆ∞Ôºö\n{context}\n\nËØ∑Êåâ‰ª•‰∏ãÊ†ºÂºèËæìÂá∫Ôºö\n{query}\nÈóªÈ¶ô: [ËØ¶ÁªÜÊèèËø∞]\nÂìÅÂë≥: [ËØ¶ÁªÜÊèèËø∞]\nÊâìÂàÜ: [90-100ÂàÜ]\n\"\"\"\n\n    response = llm_client.chat.completions.create(\n        model=model,\n        messages=[\n            {\"role\": \"system\", \"content\": \"‰Ω†ÊòØ‰∏Ä‰Ωç‰∏ì‰∏öÁöÑÂ®ÅÂ£´ÂøåÂìÅÈâ¥Â∏àÔºåÊìÖÈïøÁîüÊàêËØ¶ÁªÜÂáÜÁ°ÆÁöÑÂìÅÈâ¥Á¨îËÆ∞„ÄÇ\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        temperature=0.7,\n        max_tokens=1000\n    )\n\n    return response.choices[0].message.content\n\n\n\ndef run_conversation(query, api_key, model):\n    \"\"\"Generate whisky tasting notes in English format\"\"\"\n\n    query_embedding = get_embedding(query, api_key)\n    similar_reviews = find_similar_chunks(\n        query_embedding=query_embedding,\n        db_path=\"data/whisky_database.duckdb\",\n        table_name=\"whiskyfun_embed\",\n        text_col=\"full\",\n        embedding_col=\"bottle_embedding\"\n    )\n\n    context = \"\\n---\\n\".join([review[0] for review in similar_reviews])\n\n    prompt = f\"\"\"As a whisky expert, generate professional tasting notes for \"{query}\" based on these reference reviews:\n\nReference reviews:\n{context}\n\nPlease output in this format:\nColour: [detailed description]\nNose: [detailed aroma description]\nMouth: [detailed taste description]\nFinish: [detailed finish description]\nComments: [overall impression]\nSGP: xxx - xx points\n\"\"\"\n\n    response = llm_client.chat.completions.create(\n        model=model,\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a professional whisky taster specializing in detailed sensory analysis.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        temperature=0.7,\n        max_tokens=1200\n    )\n\n    return response.choices[0].message.content\n\n\n\n\n\n\nThe application uses a separate LLM for generating whisky recommendations:\ndef recommend_whiskies_by_profile(tasting_notes, api_key, model):\n    \"\"\"Generate whisky recommendations based on tasting profile\"\"\"\n\n    prompt = f\"\"\"Based on these tasting notes, recommend 2 similar whiskies that the user might enjoy:\n\n{Tasting Notes:}\n{tasting_notes}\n\nPlease provide:\n1. Whisky name with brief description\n2. Why it matches the user's preference\n3. Price range and availability\n\nFormat each recommendation as:\n**Recommendation [1/2]:** [Whisky Name]\n**Why it matches:** [detailed reasoning]\n**Details:** [price, availability, tasting profile]\n\"\"\"\n\n    response = recommendation_client.chat.completions.create(\n        model=model,  # Different model for recommendations\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a whisky recommendation expert with deep knowledge of global whisky brands and profiles.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        temperature=0.8,\n        max_tokens=800\n    )\n\n    return response.choices[0].message.content\n\n\n\n\n\n\n# Main application interface\ndef main():\n    st.set_page_config(\n        page_title=\"AI Whisky Tasting System\",\n        page_icon=\"ü•É\",\n        layout=\"wide\"\n    )\n\n    # Sidebar for agent selection\n    with st.sidebar:\n        st.header(\"ü•É Whisky AI Tasting\")\n\n        # Agent selection\n        agent_type = st.selectbox(\n            \"Select Tasting Agent:\",\n            [\"DrunkTony (‰∏≠Êñá)\", \"WhiskyFunny (English)\", \"WhiskyNotebook (English)\"],\n            help=\"Each agent has different personality and data sources\"\n        )\n\n        # Model selection\n        model_options = get_model_options(agent_type)\n        selected_model = st.selectbox(\"Model:\", model_options)\n\n    # Main content area\n    st.header(\"Professional Whisky Tasting Notes Generator\")\n\n    # Input section\n    col1, col2 = st.columns([2, 1])\n    with col1:\n        whisky_name = st.text_input(\n            \"Enter whisky name:\",\n            placeholder=\"e.g., Macallan 18 Year Old\",\n            help=\"Enter the full whisky name including age and cask type\"\n        )\n\n    with col2:\n        st.write(\"\")  # Spacer\n        generate_btn = st.button(\"üç∑ Generate Tasting Notes\", type=\"primary\")\n        recommend_btn = st.button(\"üéØ Get Recommendations\")\n\n    # Output sections\n    if generate_btn:\n        if not whisky_name:\n            st.error(\"Please enter a whisky name\")\n        else:\n            with st.spinner(\"Analyzing whisky...\"):\n                tasting_notes = generate_tasting_notes(whisky_name, agent_type, selected_model)\n                st.markdown(\"### ü•É Tasting Notes\")\n                st.markdown(tasting_notes)\n\n    if recommend_btn:\n        with st.spinner(\"Finding recommendations...\"):\n            recommendations = get_recommendations(tasting_notes, agent_type)\n            st.markdown(\"### üéØ Personalized Recommendations\")\n            st.markdown(recommendations)\n\n\n\nTasting Results and Recommendations\n\n\n\n\n\n\n\n\n# Rate limiting implementation\nRATE_LIMIT_FILE = \"rate_limit.json\"\nMAX_RUNS_PER_DAY = 80\n\ndef get_rate_limit_data():\n    \"\"\"Get current usage data\"\"\"\n    try:\n        with open(RATE_LIMIT_FILE, \"r\") as f:\n            data = json.load(f)\n            # Ensure keys exist\n            if \"date\" not in data or \"count\" not in data:\n                return {\"date\": str(datetime.date.today()), \"count\": 0}\n            return data\n    except (FileNotFoundError, json.JSONDecodeError):\n        return {\"date\": str(datetime.date.today()), \"count\": 0}\n\ndef check_rate_limit():\n    \"\"\"Check if user has exceeded daily limit\"\"\"\n    data = get_rate_limit_data()\n    today = str(datetime.date.today())\n\n    if data[\"date\"] != today:\n        # Reset counter for new day\n        return {\"date\": today, \"count\": 0, \"can_run\": True}\n\n    if data[\"count\"] &gt;= MAX_RUNS_PER_DAY:\n        return {\"date\": today, \"count\": data[\"count\"], \"can_run\": False}\n\n    return {\"date\": today, \"count\": data[\"count\"], \"can_run\": True}\n\n\n\n\n\n\n# Optimized similarity search with batching\ndef batch_similarity_search(query_embedding, db_path, table_name, batch_size=1000):\n    \"\"\"Optimized similarity search with batching for large datasets\"\"\"\n\n    with duckdb.connect(database=db_path, read_only=True) as con:\n        # Get total row count\n        total_rows = con.execute(f\"SELECT COUNT(*) FROM {table_name}\").fetchone()[0]\n\n        all_similarities = []\n\n        # Process in batches to manage memory\n        for offset in range(0, total_rows, batch_size):\n            batch_df = con.execute(\n                f'SELECT full, bottle_embedding FROM {table_name} LIMIT {batch_size} OFFSET {offset}'\n            ).fetchdf()\n\n            # Calculate similarities for batch\n            for _, row in batch_df.iterrows():\n                embedding = np.array(row['bottle_embedding'])\n                similarity = cosine_similarity(query_embedding, embedding)\n                all_similarities.append((row['full'], similarity))\n\n        # Sort and return top results\n        all_similarities.sort(key=lambda x: x[1], reverse=True)\n        return all_similarities[:10]\n\n\n\n\n\n\n# Environment variables in .env file\nSILICONFLOW_API_KEY=your_siliconflow_key\nMODELSCOPE_API_KEY=your_modelscope_key\nGEMINI_API_KEY=your_gemini_key  # Optional\n\n# Database initialization\npython -c \"\nimport duckdb\nconn = duckdb.connect('data/whisky_database.duckdb')\n# Create tables with vector support\n\"\n\n\n\nThe application is deployed on multiple platforms:\n\nModelScope: https://modelscope.cn/studios/ttflying/whisky_AI_tasting\nShinyApps: https://jcflyingco.shinyapps.io/ai-whisky-tasting/\n\n\n\n\n# Alternative UI implementation using Shiny\nfrom shiny import App, ui, render, reactive, req\n\napp_ui = ui.page_fluid(\n    ui.h2(\"ü•É AI Whisky Tasting System\"),\n    ui.layout_sidebar(\n        ui.sidebar(\n            ui.input_select(\"agent\", \"Select Agent:\", [\n                \"DrunkTony (‰∏≠Êñá)\", \"WhiskyFunny (English)\", \"WhiskyNotebook (English)\"\n            ]),\n            ui.input_text(\"whisky_name\", \"Whisky Name:\", \"\"),\n            ui.input_action_button(\"generate\", \"Generate Notes\")\n        ),\n        ui.output_text_verbatim(\"tasting_notes\"),\n        ui.output_text_verbatim(\"recommendations\")\n    )\n)\n\ndef server(input, output, session):\n    @output\n    @render.text\n    def tasting_notes():\n        req(input.generate())\n        # Generate tasting notes logic\n        return generate_tasting_notes(input.whisky_name(), input.agent())\n\napp = App(app_ui, server)\n\n\n\nMobile Interface View\n\n\n\n\n\n\n\n\n\nMulti-Agent Architecture: Different AI personalities and data sources\nRAG Implementation: Retrieval-augmented generation with real whisky reviews\nVector Database: Efficient similarity search with 376MB database\nBilingual Support: Chinese and English language agents\nCost Management: Built-in rate limiting and API optimization\nProfessional Tasting Formats: Industry-standard note structures\n\n\n\n\n\n\n\nMetric\nValue\n\n\n\n\nDatabase Size\n376MB (26K+ reviews)\n\n\nEmbedding Dimension\n1024\n\n\nSearch Latency\n&lt;2 seconds\n\n\nDaily Request Limit\n80 requests\n\n\nSupport Languages\n2 (EN/ZH)\n\n\nData Sources\n3 (drinktony, whiskyfun, whiskynotes)\n\n\n\n\n\n\n\nPotential improvements for next versions:\n\nAdvanced Similarity Algorithms: Implement hybrid search with text + metadata\nUser Personalization: Learn from user preferences over time\nMobile App: Native iOS/Android applications\nReal-time Data Updates: Automated web scraping pipeline\nTasting Profile Analysis: Generate user taste profiles from preferences\nSocial Features: Share tasting notes and recommendations with community\n\n\n\n\nThis whisky tasting application demonstrates the power of combining RAG technology with specialized AI agents to create a sophisticated domain-specific system. The project showcases:\n\nAdvanced AI Architecture: Multi-agent system with different personalities\nData Engineering: Large-scale vector database management\nProfessional Knowledge: Industry-standard tasting note formats\nUser Experience: Clean, intuitive interfaces across platforms\nCost Efficiency: Smart rate limiting and optimization\n\nWhether you‚Äôre a whisky enthusiast, AI developer, or data scientist, this project provides an excellent example of building production-grade AI applications that combine real-world data with advanced machine learning techniques.\n\nLive Demos: - ModelScope - ShinyApps\nTechnology Stack: Python, Streamlit, DuckDB, OpenAI API, Vector Embeddings Database: 26K+ real whisky reviews across 3 specialized sources"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#core-architecture",
    "href": "posts/whisky-tasting/index.html#core-architecture",
    "title": "Whisky Tasting note with RAG",
    "section": "",
    "text": "The application features three specialized AI agents, each with unique characteristics and data sources:\n\nDrunkTony (dt) - Chinese-language agent specializing in Chinese whisky reviews\nWhiskyFunny (wf) - English-language agent with data from whiskyfun.com\nWhiskyNotebook (wn) - English-language agent with data from whiskynotes.be\n\n\n\n\n\nPrimary Language: Python 3.13+\nWeb Framework: Streamlit (primary) + Shiny for Python (alternative)\nDatabase: DuckDB (376MB, optimized for vector operations)\nAI/ML: OpenAI API, Vector embeddings, RAG system\nData Sources: Web scraping with BeautifulSoup4\n\n\n\n\nAI Agent Configuration Panel"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#database-architecture",
    "href": "posts/whisky-tasting/index.html#database-architecture",
    "title": "Whisky Tasting note with RAG",
    "section": "",
    "text": "The system uses DuckDB as its primary database, chosen for its excellent performance with vector operations:\n-- Database structure\nCREATE TABLE drinktony_embed (\n    full TEXT,\n    bottle_embedding FLOAT[1024]  -- 1024-dimensional vectors\n);\n\nCREATE TABLE whiskyfun_embed (\n    full TEXT,\n    bottle_embedding FLOAT[1024]\n);\n\nCREATE TABLE whiskynote_embed (\n    full TEXT,\n    bottle_embedding FLOAT[1024]\n);\n\n\n\n# Web scraping example from get_data_dt.py\ndef scrape_drinktony_reviews():\n    \"\"\"Scrape Chinese whisky reviews from drinktony.netlify.app\"\"\"\n    url = \"https://drinktony.netlify.app/\"\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, \"html.parser\")\n\n    # Find all review links\n    post_links = [urljoin(url, a.get(\"href\"))\n                 for a in soup.select(\"a.quarto-grid-link\")]\n\n    all_reviews = []\n    for post_url in post_links:\n        response = requests.get(post_url)\n        soup = BeautifulSoup(response.content, \"html.parser\")\n\n        # Extract review sections\n        review_sections = soup.select(\"section.level1\")\n        for section in review_sections:\n            # Parse whisky name and review content\n            whisky_name = extract_whisky_name(section)\n            review_text = extract_review_text(section)\n            all_reviews.append({\n                'whisky': whisky_name,\n                'review': review_text\n            })\n\n    return all_reviews"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#aiml-implementation",
    "href": "posts/whisky-tasting/index.html#aiml-implementation",
    "title": "Whisky Tasting note with RAG",
    "section": "",
    "text": "The application uses state-of-the-art embedding technology to convert text into high-dimensional vectors for semantic similarity search.\n\n\nModel: BAAI/bge-large-zh-v1.5 - Dimensions: 1024 - Provider: SiliconFlow API - Purpose: Cross-lingual text understanding (works well for both Chinese and English)\n\n\n\n\nCross-lingual Capability: Excels at understanding both Chinese and English whisky terminology\nHigh Performance: Superior semantic understanding compared to generic embeddings\nEfficient Size: 1024 dimensions balance between performance and storage efficiency\nAPI Access: Stable service via SiliconFlow\n\n\n\n\nThe application uses BGE-Large-ZH-v1.5 model for generating embeddings:\ndef get_embedding(text: str, api_key: str):\n    \"\"\"Generate text embeddings using SiliconFlow API\"\"\"\n    client = OpenAI(\n        api_key=api_key,\n        base_url=\"https://api.siliconflow.cn/v1\"\n    )\n    response = client.embeddings.create(\n        model=\"BAAI/bge-large-zh-v1.5\",\n        input=[text]\n    )\n    return np.array(response.data[0].embedding)\n\ndef cosine_similarity(v1, v2):\n    \"\"\"Calculate cosine similarity between two vectors\"\"\"\n    if v1 is None or v2 is None:\n        return 0\n    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n\n\n\n\nThe Retrieval-Augmented Generation (RAG) system is the core innovation of this application. Let‚Äôs explore its components in detail.\n\n\n\nThe Retrieval-Augmented Generation process follows these steps:\n%%| fig-cap: \"RAG Workflow for Whisky Tasting\"\nflowchart TD\n    A[User Input&lt;br/&gt;Whisky Name] --&gt; B[Generate Embedding]\n    B --&gt; C[Vector Similarity Search&lt;br/&gt;in DuckDB]\n    C --&gt; D[Retrieve Top 10&lt;br/&gt;Similar Reviews]\n    D --&gt; E[Format Context for LLM]\n    E --&gt; F[Generate Tasting Notes&lt;br/&gt;with Primary LLM]\n    F --&gt; G[Generate Recommendations&lt;br/&gt;with Secondary LLM]\n    G --&gt; H[Display Results&lt;br/&gt;with Formatting]\n\n    C --&gt; I[Databases]\n    I --&gt; J[drinktony_embed&lt;br/&gt;1.2K Chinese reviews]\n    I --&gt; K[whiskyfun_embed&lt;br/&gt;20K English reviews]\n    I --&gt; L[whiskynote_embed&lt;br/&gt;5K English reviews]\n\n\n\ndef find_similar_chunks(\n    query_embedding,\n    db_path,\n    table_name,\n    text_col,\n    embedding_col,\n    top_n=10,\n):\n    \"\"\"Find most similar chunks in database using cosine similarity\"\"\"\n    try:\n        with duckdb.connect(database=db_path, read_only=True) as con:\n            df = con.execute(\n                f'SELECT \"{text_col}\", \"{embedding_col}\" FROM \"{table_name}\"'\n            ).fetchdf()\n\n            # Calculate similarities\n            similarities = []\n            for _, row in df.iterrows():\n                text = row[text_col]\n                embedding = np.array(row[embedding_col])\n                similarity = cosine_similarity(query_embedding, embedding)\n                similarities.append((text, similarity))\n\n            # Sort by similarity and return top N\n            similarities.sort(key=lambda x: x[1], reverse=True)\n            return similarities[:top_n]\n\n    except Exception as e:\n        print(f\"Error searching similar chunks: {e}\")\n        return []"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#specialized-agent-implementation",
    "href": "posts/whisky-tasting/index.html#specialized-agent-implementation",
    "title": "Whisky Tasting note with RAG",
    "section": "",
    "text": "def run_conversation(query, api_key, model):\n    \"\"\"Generate whisky tasting notes in Chinese format\"\"\"\n\n    # Step 1: Generate embedding and find similar reviews\n    query_embedding = get_embedding(query, api_key)\n    similar_reviews = find_similar_chunks(\n        query_embedding=query_embedding,\n        db_path=\"data/whisky_database.duckdb\",\n        table_name=\"drinktony_embed\",\n        text_col=\"full\",\n        embedding_col=\"bottle_embedding\"\n    )\n\n    # Step 2: Format context for LLM\n    context = \"\\n---\\n\".join([review[0] for review in similar_reviews])\n\n    # Step 3: Generate tasting notes\n    prompt = f\"\"\"‰Ωú‰∏∫Â®ÅÂ£´Âøå‰∏ìÂÆ∂ÔºåÂü∫‰∫é‰ª•‰∏ãÂ®ÅÂ£´ÂøåÂìÅÈâ¥Á¨îËÆ∞Ôºå‰∏∫\"{query}\"ÁîüÊàê‰∏ì‰∏öÁöÑÂìÅÈâ¥Êä•ÂëäÔºö\n\nÂèÇËÄÉÂìÅÈâ¥Á¨îËÆ∞Ôºö\n{context}\n\nËØ∑Êåâ‰ª•‰∏ãÊ†ºÂºèËæìÂá∫Ôºö\n{query}\nÈóªÈ¶ô: [ËØ¶ÁªÜÊèèËø∞]\nÂìÅÂë≥: [ËØ¶ÁªÜÊèèËø∞]\nÊâìÂàÜ: [90-100ÂàÜ]\n\"\"\"\n\n    response = llm_client.chat.completions.create(\n        model=model,\n        messages=[\n            {\"role\": \"system\", \"content\": \"‰Ω†ÊòØ‰∏Ä‰Ωç‰∏ì‰∏öÁöÑÂ®ÅÂ£´ÂøåÂìÅÈâ¥Â∏àÔºåÊìÖÈïøÁîüÊàêËØ¶ÁªÜÂáÜÁ°ÆÁöÑÂìÅÈâ¥Á¨îËÆ∞„ÄÇ\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        temperature=0.7,\n        max_tokens=1000\n    )\n\n    return response.choices[0].message.content\n\n\n\ndef run_conversation(query, api_key, model):\n    \"\"\"Generate whisky tasting notes in English format\"\"\"\n\n    query_embedding = get_embedding(query, api_key)\n    similar_reviews = find_similar_chunks(\n        query_embedding=query_embedding,\n        db_path=\"data/whisky_database.duckdb\",\n        table_name=\"whiskyfun_embed\",\n        text_col=\"full\",\n        embedding_col=\"bottle_embedding\"\n    )\n\n    context = \"\\n---\\n\".join([review[0] for review in similar_reviews])\n\n    prompt = f\"\"\"As a whisky expert, generate professional tasting notes for \"{query}\" based on these reference reviews:\n\nReference reviews:\n{context}\n\nPlease output in this format:\nColour: [detailed description]\nNose: [detailed aroma description]\nMouth: [detailed taste description]\nFinish: [detailed finish description]\nComments: [overall impression]\nSGP: xxx - xx points\n\"\"\"\n\n    response = llm_client.chat.completions.create(\n        model=model,\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a professional whisky taster specializing in detailed sensory analysis.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        temperature=0.7,\n        max_tokens=1200\n    )\n\n    return response.choices[0].message.content"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#recommendation-engine",
    "href": "posts/whisky-tasting/index.html#recommendation-engine",
    "title": "Whisky Tasting note with RAG",
    "section": "",
    "text": "The application uses a separate LLM for generating whisky recommendations:\ndef recommend_whiskies_by_profile(tasting_notes, api_key, model):\n    \"\"\"Generate whisky recommendations based on tasting profile\"\"\"\n\n    prompt = f\"\"\"Based on these tasting notes, recommend 2 similar whiskies that the user might enjoy:\n\n{Tasting Notes:}\n{tasting_notes}\n\nPlease provide:\n1. Whisky name with brief description\n2. Why it matches the user's preference\n3. Price range and availability\n\nFormat each recommendation as:\n**Recommendation [1/2]:** [Whisky Name]\n**Why it matches:** [detailed reasoning]\n**Details:** [price, availability, tasting profile]\n\"\"\"\n\n    response = recommendation_client.chat.completions.create(\n        model=model,  # Different model for recommendations\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a whisky recommendation expert with deep knowledge of global whisky brands and profiles.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        temperature=0.8,\n        max_tokens=800\n    )\n\n    return response.choices[0].message.content"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#user-interface-design",
    "href": "posts/whisky-tasting/index.html#user-interface-design",
    "title": "Whisky Tasting note with RAG",
    "section": "",
    "text": "# Main application interface\ndef main():\n    st.set_page_config(\n        page_title=\"AI Whisky Tasting System\",\n        page_icon=\"ü•É\",\n        layout=\"wide\"\n    )\n\n    # Sidebar for agent selection\n    with st.sidebar:\n        st.header(\"ü•É Whisky AI Tasting\")\n\n        # Agent selection\n        agent_type = st.selectbox(\n            \"Select Tasting Agent:\",\n            [\"DrunkTony (‰∏≠Êñá)\", \"WhiskyFunny (English)\", \"WhiskyNotebook (English)\"],\n            help=\"Each agent has different personality and data sources\"\n        )\n\n        # Model selection\n        model_options = get_model_options(agent_type)\n        selected_model = st.selectbox(\"Model:\", model_options)\n\n    # Main content area\n    st.header(\"Professional Whisky Tasting Notes Generator\")\n\n    # Input section\n    col1, col2 = st.columns([2, 1])\n    with col1:\n        whisky_name = st.text_input(\n            \"Enter whisky name:\",\n            placeholder=\"e.g., Macallan 18 Year Old\",\n            help=\"Enter the full whisky name including age and cask type\"\n        )\n\n    with col2:\n        st.write(\"\")  # Spacer\n        generate_btn = st.button(\"üç∑ Generate Tasting Notes\", type=\"primary\")\n        recommend_btn = st.button(\"üéØ Get Recommendations\")\n\n    # Output sections\n    if generate_btn:\n        if not whisky_name:\n            st.error(\"Please enter a whisky name\")\n        else:\n            with st.spinner(\"Analyzing whisky...\"):\n                tasting_notes = generate_tasting_notes(whisky_name, agent_type, selected_model)\n                st.markdown(\"### ü•É Tasting Notes\")\n                st.markdown(tasting_notes)\n\n    if recommend_btn:\n        with st.spinner(\"Finding recommendations...\"):\n            recommendations = get_recommendations(tasting_notes, agent_type)\n            st.markdown(\"### üéØ Personalized Recommendations\")\n            st.markdown(recommendations)\n\n\n\nTasting Results and Recommendations"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#rate-limiting-and-cost-management",
    "href": "posts/whisky-tasting/index.html#rate-limiting-and-cost-management",
    "title": "Whisky Tasting note with RAG",
    "section": "",
    "text": "# Rate limiting implementation\nRATE_LIMIT_FILE = \"rate_limit.json\"\nMAX_RUNS_PER_DAY = 80\n\ndef get_rate_limit_data():\n    \"\"\"Get current usage data\"\"\"\n    try:\n        with open(RATE_LIMIT_FILE, \"r\") as f:\n            data = json.load(f)\n            # Ensure keys exist\n            if \"date\" not in data or \"count\" not in data:\n                return {\"date\": str(datetime.date.today()), \"count\": 0}\n            return data\n    except (FileNotFoundError, json.JSONDecodeError):\n        return {\"date\": str(datetime.date.today()), \"count\": 0}\n\ndef check_rate_limit():\n    \"\"\"Check if user has exceeded daily limit\"\"\"\n    data = get_rate_limit_data()\n    today = str(datetime.date.today())\n\n    if data[\"date\"] != today:\n        # Reset counter for new day\n        return {\"date\": today, \"count\": 0, \"can_run\": True}\n\n    if data[\"count\"] &gt;= MAX_RUNS_PER_DAY:\n        return {\"date\": today, \"count\": data[\"count\"], \"can_run\": False}\n\n    return {\"date\": today, \"count\": data[\"count\"], \"can_run\": True}"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#performance-optimization",
    "href": "posts/whisky-tasting/index.html#performance-optimization",
    "title": "Whisky Tasting note with RAG",
    "section": "",
    "text": "# Optimized similarity search with batching\ndef batch_similarity_search(query_embedding, db_path, table_name, batch_size=1000):\n    \"\"\"Optimized similarity search with batching for large datasets\"\"\"\n\n    with duckdb.connect(database=db_path, read_only=True) as con:\n        # Get total row count\n        total_rows = con.execute(f\"SELECT COUNT(*) FROM {table_name}\").fetchone()[0]\n\n        all_similarities = []\n\n        # Process in batches to manage memory\n        for offset in range(0, total_rows, batch_size):\n            batch_df = con.execute(\n                f'SELECT full, bottle_embedding FROM {table_name} LIMIT {batch_size} OFFSET {offset}'\n            ).fetchdf()\n\n            # Calculate similarities for batch\n            for _, row in batch_df.iterrows():\n                embedding = np.array(row['bottle_embedding'])\n                similarity = cosine_similarity(query_embedding, embedding)\n                all_similarities.append((row['full'], similarity))\n\n        # Sort and return top results\n        all_similarities.sort(key=lambda x: x[1], reverse=True)\n        return all_similarities[:10]"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#deployment-and-configuration",
    "href": "posts/whisky-tasting/index.html#deployment-and-configuration",
    "title": "Whisky Tasting note with RAG",
    "section": "",
    "text": "# Environment variables in .env file\nSILICONFLOW_API_KEY=your_siliconflow_key\nMODELSCOPE_API_KEY=your_modelscope_key\nGEMINI_API_KEY=your_gemini_key  # Optional\n\n# Database initialization\npython -c \"\nimport duckdb\nconn = duckdb.connect('data/whisky_database.duckdb')\n# Create tables with vector support\n\"\n\n\n\nThe application is deployed on multiple platforms:\n\nModelScope: https://modelscope.cn/studios/ttflying/whisky_AI_tasting\nShinyApps: https://jcflyingco.shinyapps.io/ai-whisky-tasting/\n\n\n\n\n# Alternative UI implementation using Shiny\nfrom shiny import App, ui, render, reactive, req\n\napp_ui = ui.page_fluid(\n    ui.h2(\"ü•É AI Whisky Tasting System\"),\n    ui.layout_sidebar(\n        ui.sidebar(\n            ui.input_select(\"agent\", \"Select Agent:\", [\n                \"DrunkTony (‰∏≠Êñá)\", \"WhiskyFunny (English)\", \"WhiskyNotebook (English)\"\n            ]),\n            ui.input_text(\"whisky_name\", \"Whisky Name:\", \"\"),\n            ui.input_action_button(\"generate\", \"Generate Notes\")\n        ),\n        ui.output_text_verbatim(\"tasting_notes\"),\n        ui.output_text_verbatim(\"recommendations\")\n    )\n)\n\ndef server(input, output, session):\n    @output\n    @render.text\n    def tasting_notes():\n        req(input.generate())\n        # Generate tasting notes logic\n        return generate_tasting_notes(input.whisky_name(), input.agent())\n\napp = App(app_ui, server)\n\n\n\nMobile Interface View"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#technical-achievements",
    "href": "posts/whisky-tasting/index.html#technical-achievements",
    "title": "Whisky Tasting note with RAG",
    "section": "",
    "text": "Multi-Agent Architecture: Different AI personalities and data sources\nRAG Implementation: Retrieval-augmented generation with real whisky reviews\nVector Database: Efficient similarity search with 376MB database\nBilingual Support: Chinese and English language agents\nCost Management: Built-in rate limiting and API optimization\nProfessional Tasting Formats: Industry-standard note structures\n\n\n\n\n\n\n\nMetric\nValue\n\n\n\n\nDatabase Size\n376MB (26K+ reviews)\n\n\nEmbedding Dimension\n1024\n\n\nSearch Latency\n&lt;2 seconds\n\n\nDaily Request Limit\n80 requests\n\n\nSupport Languages\n2 (EN/ZH)\n\n\nData Sources\n3 (drinktony, whiskyfun, whiskynotes)"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#future-enhancements",
    "href": "posts/whisky-tasting/index.html#future-enhancements",
    "title": "Whisky Tasting note with RAG",
    "section": "",
    "text": "Potential improvements for next versions:\n\nAdvanced Similarity Algorithms: Implement hybrid search with text + metadata\nUser Personalization: Learn from user preferences over time\nMobile App: Native iOS/Android applications\nReal-time Data Updates: Automated web scraping pipeline\nTasting Profile Analysis: Generate user taste profiles from preferences\nSocial Features: Share tasting notes and recommendations with community"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#conclusion",
    "href": "posts/whisky-tasting/index.html#conclusion",
    "title": "Whisky Tasting note with RAG",
    "section": "",
    "text": "This whisky tasting application demonstrates the power of combining RAG technology with specialized AI agents to create a sophisticated domain-specific system. The project showcases:\n\nAdvanced AI Architecture: Multi-agent system with different personalities\nData Engineering: Large-scale vector database management\nProfessional Knowledge: Industry-standard tasting note formats\nUser Experience: Clean, intuitive interfaces across platforms\nCost Efficiency: Smart rate limiting and optimization\n\nWhether you‚Äôre a whisky enthusiast, AI developer, or data scientist, this project provides an excellent example of building production-grade AI applications that combine real-world data with advanced machine learning techniques.\n\nLive Demos: - ModelScope - ShinyApps\nTechnology Stack: Python, Streamlit, DuckDB, OpenAI API, Vector Embeddings Database: 26K+ real whisky reviews across 3 specialized sources"
  },
  {
    "objectID": "posts/weather-trend/index.html",
    "href": "posts/weather-trend/index.html",
    "title": "Weather Forecast App with Streamlit and AI Integration",
    "section": "",
    "text": "In this comprehensive tutorial, I‚Äôll guide you through creating a sophisticated weather forecast application that combines modern web development with artificial intelligence. This project demonstrates how to build a production-ready weather app with interactive maps, bilingual support, real-time data visualization, and AI-powered weather insights.\nLive Demo: https://weather-trend.streamlit.app/\nGithub: https://github.com/JCwinning/weather_trend\n\n\n\nWeather Forecast App Main Interface\n\n\nThis weather forecast application goes beyond basic weather data by integrating multiple advanced features:\n\nInteractive Location Selection: Click anywhere on the map or search by city name\nBilingual Interface: Full English/Chinese language support with toggle functionality\nAI-Powered Insights: Weather analysis and recommendations using DeepSeek AI\nAdvanced Visualization: Temperature trends, air quality monitoring, and rain probability\nReal-time Data: 7-day historical and 5-day forecast data\nResponsive Design: Works seamlessly across desktop, tablet, and mobile devices\n\n\n\n\n\n\n\n\nflowchart TD\n    A[User Interface&lt;br/&gt;Streamlit Web App] --&gt; B[Location Services]\n    A --&gt; C[Weather Data API]\n    A --&gt; D[AI Integration Layer]\n    A --&gt; E[Visualization Engine]\n\n    B --&gt; F[Interactive Map&lt;br/&gt;Folium + OpenStreetMap]\n    B --&gt; G[City Search&lt;br/&gt;Nominatim Geocoding]\n\n    C --&gt; H[Open-Meteo API&lt;br/&gt;Weather + Air Quality]\n    C --&gt; I[Data Processing&lt;br/&gt;Pandas DataFrame]\n\n    D --&gt; J[ModelScope API&lt;br/&gt;DeepSeek-V3.2 AI]\n    D --&gt; K[Intelligent Analysis&lt;br/&gt;Weather Recommendations]\n\n    E --&gt; L[Altair Charts&lt;br/&gt;Temperature Trends]\n    E --&gt; M[Data Tables&lt;br/&gt;Weather Details]\n\n    F --&gt; A\n    G --&gt; A\n    I --&gt; E\n    K --&gt; A\n\n\n Weather App Architecture \n\n\n\n\n\n\nFrontend Framework: Streamlit for rapid web application development\nMapping: Folium with OpenStreetMap tiles for interactive location selection\nData Visualization: Altair for professional charts and graphs\nAPI Integration: Open-Meteo for weather and air quality data\nAI Services: ModelScope API with DeepSeek-V3.2 for intelligent analysis\nGeocoding: Nominatim for address-to-coordinate conversion\nInternationalization: Custom language system for English/Chinese support\n\n\n\n\n\n\n\nBefore we dive into the code, let‚Äôs set up our development environment:\n# 1. Clone the repository\ngit clone &lt;your-repo-url&gt;\ncd weather_trend\n\n# 2. Install required packages\npip install streamlit pandas requests altair folium streamlit-folium geopy python-dotenv openai\n\n# 3. Set up environment variables for AI features\necho \"modelscope=your_api_key_here\" &gt; .env\n\n\n\n\nstreamlit: Web application framework with reactive UI components\npandas: Data manipulation and analysis for weather datasets\nrequests: HTTP client for API communication\naltair: Declarative statistical visualization library\nfolium + streamlit-folium: Interactive map integration\ngeopy: Geocoding services for location lookup\npython-dotenv: Environment variable management\nopenai: AI model integration (compatible with ModelScope)\n\n\n\n\n\n\n\nThe map functionality allows users to click anywhere and get weather data for that exact location:\nimport folium\nfrom streamlit_folium import st_folium\n\n# Create interactive map centered on default location\ndef create_interactive_map(lat=40.7128, lon=-74.0060, zoom=10):\n    \"\"\"Create an interactive Folium map\"\"\"\n    m = folium.Map(\n        location=[lat, lon],\n        zoom_start=zoom,\n        tiles=\"OpenStreetMap\"\n    )\n\n    # Add click event handler to capture coordinates\n    m.add_child(folium.LatLngPopup())\n\n    return m\n\n# Display map in Streamlit\nif 'map_data' not in st.session_state:\n    st.session_state.map_data = None\n\nmap_object = create_interactive_map()\nst_data = st_folium(map_object, width=700, height=500)\n\n# Capture clicked coordinates\nif st_data['last_clicked']:\n    lat = st_data['last_clicked']['lat']\n    lon = st_data['last_clicked']['lng']\n    st.session_state.clicked_location = (lat, lon)\n    get_weather_for_coordinates(lat, lon)\nKey Features: - Click-to-Select: Users can click anywhere on the map - Zoom Controls: Standard map navigation - Responsive Design: Adapts to different screen sizes - Coordinate Capture: Automatic extraction of clicked locations\n\n\n\nThe app supports both English and Chinese city names with intelligent fallback:\nimport re\nfrom geopy.geocoders import Nominatim\n\n# Extended Chinese character detection\ndef contains_chinese(text):\n    \"\"\"Check if text contains Chinese characters including CJK Unified Ideographs\"\"\"\n    chinese_pattern = re.compile(\n        r\"[\\u4e00-\\u9fff\\u3400-\\u4dbf\\U00020000-\\U0002a6df\\U0002a700-\\U0002b73f]\"\n    )\n    return bool(chinese_pattern.search(text))\n\n# Chinese city mapping for better geocoding\nCHINESE_CITY_MAPPING = {\n    \"Á∫ΩÁ∫¶\": \"New York\",\n    \"‰∏ú‰∫¨\": \"Tokyo\",\n    \"‰º¶Êï¶\": \"London\",\n    \"Â∑¥Èªé\": \"Paris\",\n    \"Ê¥õÊùâÁü∂\": \"Los Angeles\",\n    # ... more mappings\n}\n\ndef get_coordinates_for_city(city_name):\n    \"\"\"Get coordinates for city with multilingual support\"\"\"\n    # Check for Chinese city name mapping\n    if contains_chinese(city_name) and city_name in CHINESE_CITY_MAPPING:\n        city_name = CHINESE_CITY_MAPPING[city_name]\n\n    # Geocode the city\n    geolocator = Nominatim(user_agent=\"weather_app\")\n    try:\n        location = geolocator.geocode(city_name)\n        return (location.latitude, location.longitude) if location else None\n    except:\n        return None\nBilingual Features: - Chinese Character Detection: Advanced regex pattern for CJK characters - City Name Mapping: Translation database for major cities - Fallback Handling: Graceful degradation when geocoding fails - Unicode Support: Full international character support\n\n\n\nThe application fetches comprehensive weather data from Open-Meteo API:\nimport requests\nimport pandas as pd\n\ndef get_weather_data(latitude, longitude):\n    \"\"\"Fetch 12-day weather data (7 historical + 5 forecast)\"\"\"\n\n    # API endpoint configuration\n    url = \"https://api.open-meteo.com/v1/forecast\"\n    params = {\n        'latitude': latitude,\n        'longitude': longitude,\n        'daily': [\n            'temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean',\n            'weathercode', 'windspeed_10m_max', 'precipitation_probability_max',\n            'pm10', 'pm2_5'\n        ],\n        'timezone': 'auto',\n        'past_days': 7,  # Get historical data\n        'forecast_days': 5  # Get future forecast\n    }\n\n    try:\n        response = requests.get(url, params=params, timeout=10)\n        response.raise_for_status()\n\n        # Process response data\n        data = response.json()\n        df = process_weather_data(data)\n\n        return df\n\n    except requests.RequestException as e:\n        st.error(f\"API request failed: {e}\")\n        return None\n\ndef process_weather_data(data):\n    \"\"\"Convert API response to structured DataFrame\"\"\"\n    daily_data = data['daily']\n\n    # Create date range (historical + future)\n    dates = pd.date_range(\n        start=pd.to_datetime(daily_data['time'][0]),\n        periods=len(daily_data['time']),\n        freq='D'\n    )\n\n    # Build DataFrame\n    df = pd.DataFrame({\n        'date': dates,\n        'temperature_max': daily_data['temperature_2m_max'],\n        'temperature_min': daily_data['temperature_2m_min'],\n        'temperature_mean': daily_data['temperature_2m_mean'],\n        'weather_code': daily_data['weathercode'],\n        'wind_speed_max': daily_data['windspeed_10m_max'],\n        'rain_probability': daily_data['precipitation_probability_max'],\n        'pm2_5': daily_data.get('pm2_5', [0] * len(dates))\n    })\n\n    # Add derived columns\n    df['is_today'] = df['date'].dt.date == pd.Timestamp.now().date()\n    df['is_future'] = df['date'] &gt; pd.Timestamp.now()\n\n    return df\nData Processing Features: - Historical + Forecast: 7 days past + 5 days future - Air Quality Integration: PM2.5 and PM10 data - Derived Metrics: Today detection and future projection - Error Handling: Robust API error management\n\n\n\nTemperature trends with clear visual distinction between historical and forecast data:\nimport altair as alt\n\ndef create_temperature_chart(weather_df):\n    \"\"\"Create interactive temperature trend chart\"\"\"\n\n    # Base chart with temperature line\n    base_chart = alt.Chart(weather_df).mark_line(\n        point=True,\n        strokeWidth=3,\n        opacity=0.8\n    ).encode(\n        x=alt.X('date:T', title='Date'),\n        y=alt.Y('temperature_mean:Q', title='Temperature (¬∞C)', scale=alt.Scale(domain=[weather_df['temperature_min'].min()-5, weather_df['temperature_max'].max()+5]))\n    ).properties(\n        width=800,\n        height=400,\n        title='Temperature Trends'\n    )\n\n    # Historical data (solid line)\n    historical_data = weather_df[weather_df['is_future'] == False]\n    historical_line = base_chart.transform_filter(\n        'datum.is_future == false'\n    ).encode(\n        color=alt.value('blue'),\n        strokeDash=alt.value([0])  # Solid line\n    )\n\n    # Future forecast (dotted line)\n    future_data = weather_df[weather_df['is_future'] == True]\n    future_line = base_chart.transform_filter(\n        'datum.is_future == true'\n    ).encode(\n        color=alt.value('red'),\n        strokeDash=alt.value([5, 5])  # Dotted line\n    )\n\n    # Today indicator\n    today_line = alt.Chart(pd.DataFrame({'x': [pd.Timestamp.now()]})).mark_rule(\n        strokeDash=[2, 2],\n        stroke='green',\n        strokeWidth=2\n    ).encode(x='x:T')\n\n    return (historical_line + future_line + today_line).resolve_scale(color='independent')\nVisualization Features: - Line Style Differentiation: Solid (historical) vs Dotted (forecast) - Today Indicator: Clear visual marker for current day - Color Coding: Blue for past, red for future - Interactive Tooltips: Hover information for data points\n\n\n\nPM2.5 levels with EPA-compliant color coding:\ndef get_air_quality_level(pm25_value):\n    \"\"\"Get air quality level based on US EPA PM2.5 standards\"\"\"\n\n    if pm25_value &lt;= 12:\n        return {\n            'level': 'Good',\n            'color': '#00e400',  # Deeper green\n            'text_color': 'white',\n            'icon': 'üü¢'\n        }\n    elif pm25_value &lt;= 35.4:\n        return {\n            'level': 'Moderate',\n            'color': '#ffff00',  # Light green\n            'text_color': 'black',\n            'icon': 'üü¢'\n        }\n    elif pm25_value &lt;= 55.4:\n        return {\n            'level': 'Unhealthy for Sensitive Groups',\n            'color': '#ff7e00',  # Darker yellow\n            'text_color': 'black',\n            'icon': 'üü°'\n        }\n    elif pm25_value &lt;= 150.4:\n        return {\n            'level': 'Unhealthy',\n            'color': '#ff0000',  # Darker orange\n            'text_color': 'white',\n            'icon': 'üü†'\n        }\n    elif pm25_value &lt;= 250.4:\n        return {\n            'level': 'Very Unhealthy',\n            'color': '#8f3f97',  # Darker red\n            'text_color': 'white',\n            'icon': 'üî¥'\n        }\n    else:\n        return {\n            'level': 'Hazardous',\n            'color': '#7e0023',  # Very dark red\n            'text_color': 'white',\n            'icon': '‚ö´'\n        }\n\ndef display_air_quality_badge(pm25_value):\n    \"\"\"Display air quality with visual indicators\"\"\"\n    aq_info = get_air_quality_level(pm25_value)\n\n    st.markdown(f\"\"\"\n    &lt;div style=\"background-color: {aq_info['color']}; color: {aq_info['text_color']};\n                padding: 10px; border-radius: 5px; text-align: center; margin: 5px 0;\"&gt;\n        &lt;strong&gt;{aq_info['icon']} PM2.5: {pm25_value} Œºg/m¬≥&lt;/strong&gt;&lt;br&gt;\n        &lt;small&gt;{aq_info['level']}&lt;/small&gt;\n    &lt;/div&gt;\n    \"\"\", unsafe_allow_html=True)\nAir Quality Features: - EPA Standards: Based on US Environmental Protection Agency - Visual Indicators: Color-coded badges with icons - Accessibility: High contrast colors for readability - Educational: Level descriptions for user understanding\n\n\n\n\n\n\nThe most innovative feature is AI-powered weather analysis using ModelScope‚Äôs DeepSeek-V3.2 model:\n\n\n\nAI Weather Recommendations\n\n\nfrom openai import OpenAI\nimport os\n\n# Initialize AI client with ModelScope\ndef init_ai_client():\n    \"\"\"Initialize OpenAI client for ModelScope API\"\"\"\n    return OpenAI(\n        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n        api_key=os.getenv(\"modelscope\"),\n    )\n\ndef generate_weather_insights(weather_df, location_name, language=\"en\"):\n    \"\"\"Generate AI-powered weather recommendations\"\"\"\n\n    # Prepare weather data for AI analysis\n    today_index = weather_df[weather_df['is_today']].index[0] if any(weather_df['is_today']) else 0\n    historical_data = weather_df.iloc[:today_index+1]  # Up to today\n    future_data = weather_df.iloc[today_index:]  # Today onwards\n\n    # Create weather summary for AI\n    weather_summary = f\"\"\"\n    Location: {location_name}\n\n    Historical Weather (Last {len(historical_data)} days):\n    - Temperature Range: {historical_data['temperature_min'].min():.1f}¬∞C to {historical_data['temperature_max'].max():.1f}¬∞C\n    - Average Temperature: {historical_data['temperature_mean'].mean():.1f}¬∞C\n    - Air Quality Range: {historical_data['pm2_5'].min():.1f} to {historical_data['pm2_5'].max():.1f} PM2.5\n\n    Forecast (Next {len(future_data)} days):\n    - Temperature Range: {future_data['temperature_min'].min():.1f}¬∞C to {future_data['temperature_max'].max():.1f}¬∞C\n    - Average Rain Probability: {future_data['rain_probability'].mean():.0f}%\n    \"\"\"\n\n    # Generate prompt based on language\n    if language == \"zh\":\n        prompt = f\"\"\"\n        Âü∫‰∫é‰ª•‰∏ãÂ§©Ê∞îÊï∞ÊçÆÔºåËØ∑Êèê‰æõÁÆÄÊ¥ÅÂÆûÁî®ÁöÑÂ§©Ê∞îÂª∫ËÆÆÔºà100-200Â≠óÔºâÔºö\n\n        {weather_summary}\n\n        ËØ∑ÂåÖÊã¨Ôºö\n        1. Â§©Ê∞îÊ®°ÂºèÂàÜÊûê\n        2. Á©øË°£Âª∫ËÆÆ\n        3. Êà∑Â§ñÊ¥ªÂä®Âª∫ËÆÆ\n        4. ÂÅ•Â∫∑Ê≥®ÊÑè‰∫ãÈ°πÔºàÂ¶ÇÁ©∫Ê∞îË¥®ÈáèÁõ∏ÂÖ≥Ôºâ\n\n        ËØ∑Áî®‰∏≠ÊñáÂõûÂ§çÔºåËØ≠Ê∞îÂèãÂ•ΩÂÆûÁî®„ÄÇ\n        \"\"\"\n    else:\n        prompt = f\"\"\"\n        Based on the following weather data, please provide concise and practical weather advice (100-200 words):\n\n        {weather_summary}\n\n        Please include:\n        1. Weather pattern analysis\n        2. Clothing recommendations\n        3. Outdoor activity suggestions\n        4. Health considerations (related to air quality if applicable)\n\n        Please respond in {language} with a friendly and practical tone.\n        \"\"\"\n\n    try:\n        client = init_ai_client()\n        response = client.chat.completions.create(\n            model=\"deepseek-ai/DeepSeek-V3\",\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            max_tokens=300,\n            temperature=0.7\n        )\n\n        return response.choices[0].message.content\n\n    except Exception as e:\n        return f\"AI service temporarily unavailable. Error: {str(e)}\"\n\n# In Streamlit app\nif st.button(get_text(\"ai_button\", language)):\n    with st.spinner(\"Getting AI weather advice...\"):\n        if 'weather_df' in st.session_state and 'location_name' in st.session_state:\n            ai_insights = generate_weather_insights(\n                st.session_state.weather_df,\n                st.session_state.location_name,\n                language\n            )\n            st.markdown(\"### ü§ñ AI Weather Analysis\")\n            st.write(ai_insights)\n        else:\n            st.warning(\"Please get weather data first.\")\nAI Features: - Context-Aware Analysis: Processes both historical and forecast data - Multilingual Support: AI responds in user‚Äôs selected language - Practical Recommendations: Clothing, activities, and health advice - Error Handling: Graceful fallback when AI service unavailable\n\n\n\nThe AI system uses carefully crafted prompts to generate useful insights:\nPrompt Structure: 1. Data Context: Comprehensive weather statistics 2. Task Definition: Clear requirements for analysis 3. Output Format: Structured response categories 4. Language Adaptation: Matches user interface language\nResponse Categories: - Weather Pattern Analysis: Trends and anomalies - Clothing Recommendations: Practical dress suggestions - Activity Advice: Outdoor planning recommendations - Health Considerations: Air quality and weather impacts\n\n\n\n\n\n\nThe app implements a comprehensive bilingual system:\n# language.py - Translation management\nTRANSLATIONS = {\n    \"en\": {\n        \"app_title\": \"Weather Forecast App\",\n        \"sidebar_header\": \"Weather Query\",\n        \"city_input_placeholder\": \"Enter a city name\",\n        \"get_weather_button\": \"Get Weather\",\n        \"weather_trends_title\": \"Weather Trends for\",\n        \"ai_button\": \"AI Weather Advice\",\n        # ... more translations\n    },\n    \"zh\": {\n        \"app_title\": \"Â§©Ê∞îÈ¢ÑÊä•Â∫îÁî®\",\n        \"sidebar_header\": \"Â§©Ê∞îÊü•ËØ¢\",\n        \"city_input_placeholder\": \"ËæìÂÖ•ÂüéÂ∏ÇÂêçÁß∞\",\n        \"get_weather_button\": \"Ëé∑ÂèñÂ§©Ê∞î\",\n        \"weather_trends_title\": \"Â§©Ê∞îË∂ãÂäø\",\n        \"ai_button\": \"AIÂ§©Ê∞îÂª∫ËÆÆ\",\n        # ... more translations\n    }\n}\n\ndef get_text(key, language=\"en\"):\n    \"\"\"Get translated text for given key and language\"\"\"\n    return TRANSLATIONS.get(language, {}).get(key, key)\n\ndef get_available_languages():\n    \"\"\"Get available language options\"\"\"\n    return {\"en\": \"English\", \"zh\": \"‰∏≠Êñá\"}\n\n# In main app (app.py)\ndef main():\n    # Language state management\n    if 'language' not in st.session_state:\n        st.session_state.language = \"en\"\n\n    # Language toggle button\n    current_lang = st.session_state.language\n    available_langs = get_available_languages()\n\n    col1, col2, col3 = st.columns([1,1,6])\n    with col1:\n        if st.button(\"EN\", disabled=current_lang==\"en\"):\n            st.session_state.language = \"en\"\n            st.rerun()\n\n    with col2:\n        if st.button(\"‰∏≠Êñá\", disabled=current_lang==\"zh\"):\n            st.session_state.language = \"zh\"\n            st.rerun()\n\n    # Use current language for all UI elements\n    language = st.session_state.language\n    st.title(get_text(\"app_title\", language))\n    st.sidebar.header(get_text(\"sidebar_header\", language))\nInternationalization Features: - Complete UI Translation: All interface elements localized - Dynamic Language Switching: Instant UI updates on language change - Chinese Character Support: Full Unicode and CJK support - Consistent Language: AI responses match UI language\n\n\n\n\n\n\nThe weather table combines data with visual elements for quick understanding:\ndef create_weather_table(weather_df, language=\"en\"):\n    \"\"\"Create enhanced weather table with icons and colors\"\"\"\n\n    # Weather code to emoji mapping\n    WEATHER_ICONS = {\n        0: \"‚òÄÔ∏è\",   # Clear sky\n        1: \"‚õÖ\",   # Mainly clear\n        2: \"‚òÅÔ∏è\",   # Partly cloudy\n        3: \"‚òÅÔ∏è\",   # Overcast\n        45: \"üå´Ô∏è\",  # Fog\n        48: \"üå¶Ô∏è\",  # Drizzle\n        51: \"üåßÔ∏è\",  # Rain\n        53: \"‚ùÑÔ∏è\",  # Snow\n        95: \"‚õàÔ∏è\",  # Thunderstorm\n    }\n\n    def format_weather_row(row):\n        \"\"\"Format individual weather row with styling\"\"\"\n        date_str = row['date'].strftime('%Y-%m-%d')\n        temp_range = f\"{row['temperature_min']:.1f}¬∞ ~ {row['temperature_max']:.1f}¬∞\"\n        weather_icon = WEATHER_ICONS.get(row['weather_code'], \"üå°Ô∏è\")\n\n        # Air quality badge\n        aq_info = get_air_quality_level(row['pm2_5'])\n        aq_badge = f'&lt;span style=\"background-color: {aq_info[\"color\"]}; color: {aq_info[\"text_color\"]}; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;\"&gt;{aq_info[\"icon\"]} {row[\"pm2_5\"]:.0f}&lt;/span&gt;'\n\n        # Rain probability indicator\n        rain_color = 'red' if row['rain_probability'] &gt;= 80 else 'orange' if row['rain_probability'] &gt;= 50 else 'gray'\n        rain_indicator = f'&lt;span style=\"color: {rain_color};\"&gt;üî¥ {row[\"rain_probability\"]:.0f}%&lt;/span&gt;' if row['rain_probability'] &gt;= 50 else f'&lt;span style=\"color: {rain_color};\"&gt;üü¢ {row[\"rain_probability\"]:.0f}%&lt;/span&gt;'\n\n        # Today highlighting\n        row_style = 'font-size: 1.2em; font-weight: bold;' if row['is_today'] else ''\n\n        return {\n            'Date': f'&lt;span style=\"{row_style}\"&gt;{date_str}&lt;/span&gt;',\n            'Weather': f'&lt;span style=\"{row_style}\"&gt;{weather_icon}&lt;/span&gt;',\n            'Temperature': f'&lt;span style=\"{row_style}\"&gt;{temp_range}&lt;/span&gt;',\n            'Wind': f'&lt;span style=\"{row_style}\"&gt;üí® {row[\"wind_speed_max\"]:.1f} km/h&lt;/span&gt;',\n            'Rain': rain_indicator,\n            'Air Quality': aq_badge\n        }\n\n    # Apply formatting to all rows\n    formatted_rows = [format_weather_row(row) for _, row in weather_df.iterrows()]\n\n    return pd.DataFrame(formatted_rows)\n\n# Display in Streamlit\nst.markdown(\"### üìä Weather Details\")\nst.dataframe(\n    create_weather_table(weather_df, language),\n    width=1200,\n    hide_index=True,\n    unsafe_allow_html=True\n)\nTable Features: - Weather Icons: Emoji representation for quick visual understanding - Today Highlighting: Larger, bold text for current day - Air Quality Badges: Color-coded PM2.5 indicators - Rain Probability: Visual indicators with Material Design colors - Responsive Layout: Adapts to different screen sizes\n\n\n\n\n\n\nFor production deployment, configure environment variables:\n# .env file\nmodelscope=your_modelscope_api_key_here\n\n# Additional production settings\n# Consider rate limiting, caching, and monitoring\n\n\n\n# 1. Install Streamlit CLI\npip install streamlit\n\n# 2. Login to Streamlit\nstreamlit login\n\n# 3. Deploy to Streamlit Cloud\nstreamlit run app.py  # Test locally first\n# Then deploy through cloud.streamlit.io or using CLI\n\n\n\nFROM python:3.9-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY . .\n\nEXPOSE 8501\n\nCMD [\"streamlit\", \"run\", \"app.py\", \"--server.address\", \"0.0.0.0\"]\n\n\n\n\n\n\n@st.cache_data(ttl=3600)  # Cache for 1 hour\ndef get_weather_data_cached(lat, lon):\n    \"\"\"Cached weather data fetching\"\"\"\n    return get_weather_data(lat, lon)\n\n@st.cache_resource\ndef get_ai_client():\n    \"\"\"Cached AI client initialization\"\"\"\n    return init_ai_client()\n\n# Cache map generation\n@st.cache_data(ttl=3600)\ndef create_map_cached(lat, lon):\n    \"\"\"Cached map creation\"\"\"\n    return create_interactive_map(lat, lon)\n\n\n\ndef robust_api_call(func, *args, max_retries=3, **kwargs):\n    \"\"\"Robust API calling with retry logic\"\"\"\n    for attempt in range(max_retries):\n        try:\n            return func(*args, **kwargs)\n        except requests.exceptions.Timeout:\n            if attempt == max_retries - 1:\n                st.error(\"Weather service temporarily unavailable\")\n                return None\n            time.sleep(2 ** attempt)  # Exponential backoff\n        except requests.exceptions.RequestException as e:\n            st.error(f\"API error: {e}\")\n            return None\n\n\n\n\n\n\n\nModular Architecture: Separate concerns (API, UI, AI, Visualization)\nError Resilience: Comprehensive error handling and fallbacks\nUser Experience: Fast loading with caching and progress indicators\nInternationalization: Plan for multilingual support from the start\nAPI Management: Rate limiting and request optimization\nResponsive Design: Test across different devices and screen sizes\nSecurity: Environment variables for sensitive data\n\n\n\n\n\nData Caching: 1-hour TTL for weather data\nLazy Loading: Load components only when needed\nAsync Operations: Non-blocking API calls where possible\nOptimization: Minimize re-renders and state updates\n\n\n\n\n\n\n\n\nExtended AI Capabilities:\n\nMulti-day activity planning\nPersonalized recommendations based on user preferences\nIntegration with calendar applications\n\nAdvanced Visualizations:\n\nWind direction and speed maps\nPrecipitation intensity charts\nHistorical weather comparisons\n\nData Sources:\n\nMultiple weather provider integration\nReal-time radar integration\nWeather alert systems\n\nUser Features:\n\nSaved locations and favorites\nWeather notifications\nHistorical data analysis\nExport functionality\n\nTechnical Enhancements:\n\nWebSocket real-time updates\nProgressive Web App (PWA) features\nOffline functionality\n\n\n\n\n\n\nThis weather forecast application demonstrates how modern web development technologies can be combined to create a comprehensive, intelligent weather service. The integration of AI-powered recommendations elevates it from a simple data display tool to a practical weather assistant that helps users make informed decisions about their daily activities.\nThe project showcases: - Modern Web Development: Streamlit for rapid prototyping - Data Visualization: Professional charts and interactive maps - AI Integration: Practical use of language models for data analysis - Internationalization: Complete bilingual support - Production Readiness: Error handling, caching, and optimization\nWhether you‚Äôre building weather applications, data dashboards, or AI-powered tools, this project provides an excellent foundation for creating sophisticated, user-friendly applications.\nLive Demo: https://weather-trend.streamlit.app/ Technology Stack: Streamlit, Altair, Folium, ModelScope AI, Open-Meteo API Source Code: Available in the weather_trend directory\n\nReady to build your own weather app? Check out the complete source code and start experimenting with these advanced features today!"
  },
  {
    "objectID": "posts/weather-trend/index.html#technical-architecture",
    "href": "posts/weather-trend/index.html#technical-architecture",
    "title": "Weather Forecast App with Streamlit and AI Integration",
    "section": "",
    "text": "flowchart TD\n    A[User Interface&lt;br/&gt;Streamlit Web App] --&gt; B[Location Services]\n    A --&gt; C[Weather Data API]\n    A --&gt; D[AI Integration Layer]\n    A --&gt; E[Visualization Engine]\n\n    B --&gt; F[Interactive Map&lt;br/&gt;Folium + OpenStreetMap]\n    B --&gt; G[City Search&lt;br/&gt;Nominatim Geocoding]\n\n    C --&gt; H[Open-Meteo API&lt;br/&gt;Weather + Air Quality]\n    C --&gt; I[Data Processing&lt;br/&gt;Pandas DataFrame]\n\n    D --&gt; J[ModelScope API&lt;br/&gt;DeepSeek-V3.2 AI]\n    D --&gt; K[Intelligent Analysis&lt;br/&gt;Weather Recommendations]\n\n    E --&gt; L[Altair Charts&lt;br/&gt;Temperature Trends]\n    E --&gt; M[Data Tables&lt;br/&gt;Weather Details]\n\n    F --&gt; A\n    G --&gt; A\n    I --&gt; E\n    K --&gt; A\n\n\n Weather App Architecture \n\n\n\n\n\n\nFrontend Framework: Streamlit for rapid web application development\nMapping: Folium with OpenStreetMap tiles for interactive location selection\nData Visualization: Altair for professional charts and graphs\nAPI Integration: Open-Meteo for weather and air quality data\nAI Services: ModelScope API with DeepSeek-V3.2 for intelligent analysis\nGeocoding: Nominatim for address-to-coordinate conversion\nInternationalization: Custom language system for English/Chinese support"
  },
  {
    "objectID": "posts/weather-trend/index.html#getting-started",
    "href": "posts/weather-trend/index.html#getting-started",
    "title": "Weather Forecast App with Streamlit and AI Integration",
    "section": "",
    "text": "Before we dive into the code, let‚Äôs set up our development environment:\n# 1. Clone the repository\ngit clone &lt;your-repo-url&gt;\ncd weather_trend\n\n# 2. Install required packages\npip install streamlit pandas requests altair folium streamlit-folium geopy python-dotenv openai\n\n# 3. Set up environment variables for AI features\necho \"modelscope=your_api_key_here\" &gt; .env\n\n\n\n\nstreamlit: Web application framework with reactive UI components\npandas: Data manipulation and analysis for weather datasets\nrequests: HTTP client for API communication\naltair: Declarative statistical visualization library\nfolium + streamlit-folium: Interactive map integration\ngeopy: Geocoding services for location lookup\npython-dotenv: Environment variable management\nopenai: AI model integration (compatible with ModelScope)"
  },
  {
    "objectID": "posts/weather-trend/index.html#core-features-implementation",
    "href": "posts/weather-trend/index.html#core-features-implementation",
    "title": "Weather Forecast App with Streamlit and AI Integration",
    "section": "",
    "text": "The map functionality allows users to click anywhere and get weather data for that exact location:\nimport folium\nfrom streamlit_folium import st_folium\n\n# Create interactive map centered on default location\ndef create_interactive_map(lat=40.7128, lon=-74.0060, zoom=10):\n    \"\"\"Create an interactive Folium map\"\"\"\n    m = folium.Map(\n        location=[lat, lon],\n        zoom_start=zoom,\n        tiles=\"OpenStreetMap\"\n    )\n\n    # Add click event handler to capture coordinates\n    m.add_child(folium.LatLngPopup())\n\n    return m\n\n# Display map in Streamlit\nif 'map_data' not in st.session_state:\n    st.session_state.map_data = None\n\nmap_object = create_interactive_map()\nst_data = st_folium(map_object, width=700, height=500)\n\n# Capture clicked coordinates\nif st_data['last_clicked']:\n    lat = st_data['last_clicked']['lat']\n    lon = st_data['last_clicked']['lng']\n    st.session_state.clicked_location = (lat, lon)\n    get_weather_for_coordinates(lat, lon)\nKey Features: - Click-to-Select: Users can click anywhere on the map - Zoom Controls: Standard map navigation - Responsive Design: Adapts to different screen sizes - Coordinate Capture: Automatic extraction of clicked locations\n\n\n\nThe app supports both English and Chinese city names with intelligent fallback:\nimport re\nfrom geopy.geocoders import Nominatim\n\n# Extended Chinese character detection\ndef contains_chinese(text):\n    \"\"\"Check if text contains Chinese characters including CJK Unified Ideographs\"\"\"\n    chinese_pattern = re.compile(\n        r\"[\\u4e00-\\u9fff\\u3400-\\u4dbf\\U00020000-\\U0002a6df\\U0002a700-\\U0002b73f]\"\n    )\n    return bool(chinese_pattern.search(text))\n\n# Chinese city mapping for better geocoding\nCHINESE_CITY_MAPPING = {\n    \"Á∫ΩÁ∫¶\": \"New York\",\n    \"‰∏ú‰∫¨\": \"Tokyo\",\n    \"‰º¶Êï¶\": \"London\",\n    \"Â∑¥Èªé\": \"Paris\",\n    \"Ê¥õÊùâÁü∂\": \"Los Angeles\",\n    # ... more mappings\n}\n\ndef get_coordinates_for_city(city_name):\n    \"\"\"Get coordinates for city with multilingual support\"\"\"\n    # Check for Chinese city name mapping\n    if contains_chinese(city_name) and city_name in CHINESE_CITY_MAPPING:\n        city_name = CHINESE_CITY_MAPPING[city_name]\n\n    # Geocode the city\n    geolocator = Nominatim(user_agent=\"weather_app\")\n    try:\n        location = geolocator.geocode(city_name)\n        return (location.latitude, location.longitude) if location else None\n    except:\n        return None\nBilingual Features: - Chinese Character Detection: Advanced regex pattern for CJK characters - City Name Mapping: Translation database for major cities - Fallback Handling: Graceful degradation when geocoding fails - Unicode Support: Full international character support\n\n\n\nThe application fetches comprehensive weather data from Open-Meteo API:\nimport requests\nimport pandas as pd\n\ndef get_weather_data(latitude, longitude):\n    \"\"\"Fetch 12-day weather data (7 historical + 5 forecast)\"\"\"\n\n    # API endpoint configuration\n    url = \"https://api.open-meteo.com/v1/forecast\"\n    params = {\n        'latitude': latitude,\n        'longitude': longitude,\n        'daily': [\n            'temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean',\n            'weathercode', 'windspeed_10m_max', 'precipitation_probability_max',\n            'pm10', 'pm2_5'\n        ],\n        'timezone': 'auto',\n        'past_days': 7,  # Get historical data\n        'forecast_days': 5  # Get future forecast\n    }\n\n    try:\n        response = requests.get(url, params=params, timeout=10)\n        response.raise_for_status()\n\n        # Process response data\n        data = response.json()\n        df = process_weather_data(data)\n\n        return df\n\n    except requests.RequestException as e:\n        st.error(f\"API request failed: {e}\")\n        return None\n\ndef process_weather_data(data):\n    \"\"\"Convert API response to structured DataFrame\"\"\"\n    daily_data = data['daily']\n\n    # Create date range (historical + future)\n    dates = pd.date_range(\n        start=pd.to_datetime(daily_data['time'][0]),\n        periods=len(daily_data['time']),\n        freq='D'\n    )\n\n    # Build DataFrame\n    df = pd.DataFrame({\n        'date': dates,\n        'temperature_max': daily_data['temperature_2m_max'],\n        'temperature_min': daily_data['temperature_2m_min'],\n        'temperature_mean': daily_data['temperature_2m_mean'],\n        'weather_code': daily_data['weathercode'],\n        'wind_speed_max': daily_data['windspeed_10m_max'],\n        'rain_probability': daily_data['precipitation_probability_max'],\n        'pm2_5': daily_data.get('pm2_5', [0] * len(dates))\n    })\n\n    # Add derived columns\n    df['is_today'] = df['date'].dt.date == pd.Timestamp.now().date()\n    df['is_future'] = df['date'] &gt; pd.Timestamp.now()\n\n    return df\nData Processing Features: - Historical + Forecast: 7 days past + 5 days future - Air Quality Integration: PM2.5 and PM10 data - Derived Metrics: Today detection and future projection - Error Handling: Robust API error management\n\n\n\nTemperature trends with clear visual distinction between historical and forecast data:\nimport altair as alt\n\ndef create_temperature_chart(weather_df):\n    \"\"\"Create interactive temperature trend chart\"\"\"\n\n    # Base chart with temperature line\n    base_chart = alt.Chart(weather_df).mark_line(\n        point=True,\n        strokeWidth=3,\n        opacity=0.8\n    ).encode(\n        x=alt.X('date:T', title='Date'),\n        y=alt.Y('temperature_mean:Q', title='Temperature (¬∞C)', scale=alt.Scale(domain=[weather_df['temperature_min'].min()-5, weather_df['temperature_max'].max()+5]))\n    ).properties(\n        width=800,\n        height=400,\n        title='Temperature Trends'\n    )\n\n    # Historical data (solid line)\n    historical_data = weather_df[weather_df['is_future'] == False]\n    historical_line = base_chart.transform_filter(\n        'datum.is_future == false'\n    ).encode(\n        color=alt.value('blue'),\n        strokeDash=alt.value([0])  # Solid line\n    )\n\n    # Future forecast (dotted line)\n    future_data = weather_df[weather_df['is_future'] == True]\n    future_line = base_chart.transform_filter(\n        'datum.is_future == true'\n    ).encode(\n        color=alt.value('red'),\n        strokeDash=alt.value([5, 5])  # Dotted line\n    )\n\n    # Today indicator\n    today_line = alt.Chart(pd.DataFrame({'x': [pd.Timestamp.now()]})).mark_rule(\n        strokeDash=[2, 2],\n        stroke='green',\n        strokeWidth=2\n    ).encode(x='x:T')\n\n    return (historical_line + future_line + today_line).resolve_scale(color='independent')\nVisualization Features: - Line Style Differentiation: Solid (historical) vs Dotted (forecast) - Today Indicator: Clear visual marker for current day - Color Coding: Blue for past, red for future - Interactive Tooltips: Hover information for data points\n\n\n\nPM2.5 levels with EPA-compliant color coding:\ndef get_air_quality_level(pm25_value):\n    \"\"\"Get air quality level based on US EPA PM2.5 standards\"\"\"\n\n    if pm25_value &lt;= 12:\n        return {\n            'level': 'Good',\n            'color': '#00e400',  # Deeper green\n            'text_color': 'white',\n            'icon': 'üü¢'\n        }\n    elif pm25_value &lt;= 35.4:\n        return {\n            'level': 'Moderate',\n            'color': '#ffff00',  # Light green\n            'text_color': 'black',\n            'icon': 'üü¢'\n        }\n    elif pm25_value &lt;= 55.4:\n        return {\n            'level': 'Unhealthy for Sensitive Groups',\n            'color': '#ff7e00',  # Darker yellow\n            'text_color': 'black',\n            'icon': 'üü°'\n        }\n    elif pm25_value &lt;= 150.4:\n        return {\n            'level': 'Unhealthy',\n            'color': '#ff0000',  # Darker orange\n            'text_color': 'white',\n            'icon': 'üü†'\n        }\n    elif pm25_value &lt;= 250.4:\n        return {\n            'level': 'Very Unhealthy',\n            'color': '#8f3f97',  # Darker red\n            'text_color': 'white',\n            'icon': 'üî¥'\n        }\n    else:\n        return {\n            'level': 'Hazardous',\n            'color': '#7e0023',  # Very dark red\n            'text_color': 'white',\n            'icon': '‚ö´'\n        }\n\ndef display_air_quality_badge(pm25_value):\n    \"\"\"Display air quality with visual indicators\"\"\"\n    aq_info = get_air_quality_level(pm25_value)\n\n    st.markdown(f\"\"\"\n    &lt;div style=\"background-color: {aq_info['color']}; color: {aq_info['text_color']};\n                padding: 10px; border-radius: 5px; text-align: center; margin: 5px 0;\"&gt;\n        &lt;strong&gt;{aq_info['icon']} PM2.5: {pm25_value} Œºg/m¬≥&lt;/strong&gt;&lt;br&gt;\n        &lt;small&gt;{aq_info['level']}&lt;/small&gt;\n    &lt;/div&gt;\n    \"\"\", unsafe_allow_html=True)\nAir Quality Features: - EPA Standards: Based on US Environmental Protection Agency - Visual Indicators: Color-coded badges with icons - Accessibility: High contrast colors for readability - Educational: Level descriptions for user understanding"
  },
  {
    "objectID": "posts/weather-trend/index.html#ai-powered-weather-intelligence",
    "href": "posts/weather-trend/index.html#ai-powered-weather-intelligence",
    "title": "Weather Forecast App with Streamlit and AI Integration",
    "section": "",
    "text": "The most innovative feature is AI-powered weather analysis using ModelScope‚Äôs DeepSeek-V3.2 model:\n\n\n\nAI Weather Recommendations\n\n\nfrom openai import OpenAI\nimport os\n\n# Initialize AI client with ModelScope\ndef init_ai_client():\n    \"\"\"Initialize OpenAI client for ModelScope API\"\"\"\n    return OpenAI(\n        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n        api_key=os.getenv(\"modelscope\"),\n    )\n\ndef generate_weather_insights(weather_df, location_name, language=\"en\"):\n    \"\"\"Generate AI-powered weather recommendations\"\"\"\n\n    # Prepare weather data for AI analysis\n    today_index = weather_df[weather_df['is_today']].index[0] if any(weather_df['is_today']) else 0\n    historical_data = weather_df.iloc[:today_index+1]  # Up to today\n    future_data = weather_df.iloc[today_index:]  # Today onwards\n\n    # Create weather summary for AI\n    weather_summary = f\"\"\"\n    Location: {location_name}\n\n    Historical Weather (Last {len(historical_data)} days):\n    - Temperature Range: {historical_data['temperature_min'].min():.1f}¬∞C to {historical_data['temperature_max'].max():.1f}¬∞C\n    - Average Temperature: {historical_data['temperature_mean'].mean():.1f}¬∞C\n    - Air Quality Range: {historical_data['pm2_5'].min():.1f} to {historical_data['pm2_5'].max():.1f} PM2.5\n\n    Forecast (Next {len(future_data)} days):\n    - Temperature Range: {future_data['temperature_min'].min():.1f}¬∞C to {future_data['temperature_max'].max():.1f}¬∞C\n    - Average Rain Probability: {future_data['rain_probability'].mean():.0f}%\n    \"\"\"\n\n    # Generate prompt based on language\n    if language == \"zh\":\n        prompt = f\"\"\"\n        Âü∫‰∫é‰ª•‰∏ãÂ§©Ê∞îÊï∞ÊçÆÔºåËØ∑Êèê‰æõÁÆÄÊ¥ÅÂÆûÁî®ÁöÑÂ§©Ê∞îÂª∫ËÆÆÔºà100-200Â≠óÔºâÔºö\n\n        {weather_summary}\n\n        ËØ∑ÂåÖÊã¨Ôºö\n        1. Â§©Ê∞îÊ®°ÂºèÂàÜÊûê\n        2. Á©øË°£Âª∫ËÆÆ\n        3. Êà∑Â§ñÊ¥ªÂä®Âª∫ËÆÆ\n        4. ÂÅ•Â∫∑Ê≥®ÊÑè‰∫ãÈ°πÔºàÂ¶ÇÁ©∫Ê∞îË¥®ÈáèÁõ∏ÂÖ≥Ôºâ\n\n        ËØ∑Áî®‰∏≠ÊñáÂõûÂ§çÔºåËØ≠Ê∞îÂèãÂ•ΩÂÆûÁî®„ÄÇ\n        \"\"\"\n    else:\n        prompt = f\"\"\"\n        Based on the following weather data, please provide concise and practical weather advice (100-200 words):\n\n        {weather_summary}\n\n        Please include:\n        1. Weather pattern analysis\n        2. Clothing recommendations\n        3. Outdoor activity suggestions\n        4. Health considerations (related to air quality if applicable)\n\n        Please respond in {language} with a friendly and practical tone.\n        \"\"\"\n\n    try:\n        client = init_ai_client()\n        response = client.chat.completions.create(\n            model=\"deepseek-ai/DeepSeek-V3\",\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            max_tokens=300,\n            temperature=0.7\n        )\n\n        return response.choices[0].message.content\n\n    except Exception as e:\n        return f\"AI service temporarily unavailable. Error: {str(e)}\"\n\n# In Streamlit app\nif st.button(get_text(\"ai_button\", language)):\n    with st.spinner(\"Getting AI weather advice...\"):\n        if 'weather_df' in st.session_state and 'location_name' in st.session_state:\n            ai_insights = generate_weather_insights(\n                st.session_state.weather_df,\n                st.session_state.location_name,\n                language\n            )\n            st.markdown(\"### ü§ñ AI Weather Analysis\")\n            st.write(ai_insights)\n        else:\n            st.warning(\"Please get weather data first.\")\nAI Features: - Context-Aware Analysis: Processes both historical and forecast data - Multilingual Support: AI responds in user‚Äôs selected language - Practical Recommendations: Clothing, activities, and health advice - Error Handling: Graceful fallback when AI service unavailable\n\n\n\nThe AI system uses carefully crafted prompts to generate useful insights:\nPrompt Structure: 1. Data Context: Comprehensive weather statistics 2. Task Definition: Clear requirements for analysis 3. Output Format: Structured response categories 4. Language Adaptation: Matches user interface language\nResponse Categories: - Weather Pattern Analysis: Trends and anomalies - Clothing Recommendations: Practical dress suggestions - Activity Advice: Outdoor planning recommendations - Health Considerations: Air quality and weather impacts"
  },
  {
    "objectID": "posts/weather-trend/index.html#internationalization-system",
    "href": "posts/weather-trend/index.html#internationalization-system",
    "title": "Weather Forecast App with Streamlit and AI Integration",
    "section": "",
    "text": "The app implements a comprehensive bilingual system:\n# language.py - Translation management\nTRANSLATIONS = {\n    \"en\": {\n        \"app_title\": \"Weather Forecast App\",\n        \"sidebar_header\": \"Weather Query\",\n        \"city_input_placeholder\": \"Enter a city name\",\n        \"get_weather_button\": \"Get Weather\",\n        \"weather_trends_title\": \"Weather Trends for\",\n        \"ai_button\": \"AI Weather Advice\",\n        # ... more translations\n    },\n    \"zh\": {\n        \"app_title\": \"Â§©Ê∞îÈ¢ÑÊä•Â∫îÁî®\",\n        \"sidebar_header\": \"Â§©Ê∞îÊü•ËØ¢\",\n        \"city_input_placeholder\": \"ËæìÂÖ•ÂüéÂ∏ÇÂêçÁß∞\",\n        \"get_weather_button\": \"Ëé∑ÂèñÂ§©Ê∞î\",\n        \"weather_trends_title\": \"Â§©Ê∞îË∂ãÂäø\",\n        \"ai_button\": \"AIÂ§©Ê∞îÂª∫ËÆÆ\",\n        # ... more translations\n    }\n}\n\ndef get_text(key, language=\"en\"):\n    \"\"\"Get translated text for given key and language\"\"\"\n    return TRANSLATIONS.get(language, {}).get(key, key)\n\ndef get_available_languages():\n    \"\"\"Get available language options\"\"\"\n    return {\"en\": \"English\", \"zh\": \"‰∏≠Êñá\"}\n\n# In main app (app.py)\ndef main():\n    # Language state management\n    if 'language' not in st.session_state:\n        st.session_state.language = \"en\"\n\n    # Language toggle button\n    current_lang = st.session_state.language\n    available_langs = get_available_languages()\n\n    col1, col2, col3 = st.columns([1,1,6])\n    with col1:\n        if st.button(\"EN\", disabled=current_lang==\"en\"):\n            st.session_state.language = \"en\"\n            st.rerun()\n\n    with col2:\n        if st.button(\"‰∏≠Êñá\", disabled=current_lang==\"zh\"):\n            st.session_state.language = \"zh\"\n            st.rerun()\n\n    # Use current language for all UI elements\n    language = st.session_state.language\n    st.title(get_text(\"app_title\", language))\n    st.sidebar.header(get_text(\"sidebar_header\", language))\nInternationalization Features: - Complete UI Translation: All interface elements localized - Dynamic Language Switching: Instant UI updates on language change - Chinese Character Support: Full Unicode and CJK support - Consistent Language: AI responses match UI language"
  },
  {
    "objectID": "posts/weather-trend/index.html#advanced-ui-components",
    "href": "posts/weather-trend/index.html#advanced-ui-components",
    "title": "Weather Forecast App with Streamlit and AI Integration",
    "section": "",
    "text": "The weather table combines data with visual elements for quick understanding:\ndef create_weather_table(weather_df, language=\"en\"):\n    \"\"\"Create enhanced weather table with icons and colors\"\"\"\n\n    # Weather code to emoji mapping\n    WEATHER_ICONS = {\n        0: \"‚òÄÔ∏è\",   # Clear sky\n        1: \"‚õÖ\",   # Mainly clear\n        2: \"‚òÅÔ∏è\",   # Partly cloudy\n        3: \"‚òÅÔ∏è\",   # Overcast\n        45: \"üå´Ô∏è\",  # Fog\n        48: \"üå¶Ô∏è\",  # Drizzle\n        51: \"üåßÔ∏è\",  # Rain\n        53: \"‚ùÑÔ∏è\",  # Snow\n        95: \"‚õàÔ∏è\",  # Thunderstorm\n    }\n\n    def format_weather_row(row):\n        \"\"\"Format individual weather row with styling\"\"\"\n        date_str = row['date'].strftime('%Y-%m-%d')\n        temp_range = f\"{row['temperature_min']:.1f}¬∞ ~ {row['temperature_max']:.1f}¬∞\"\n        weather_icon = WEATHER_ICONS.get(row['weather_code'], \"üå°Ô∏è\")\n\n        # Air quality badge\n        aq_info = get_air_quality_level(row['pm2_5'])\n        aq_badge = f'&lt;span style=\"background-color: {aq_info[\"color\"]}; color: {aq_info[\"text_color\"]}; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;\"&gt;{aq_info[\"icon\"]} {row[\"pm2_5\"]:.0f}&lt;/span&gt;'\n\n        # Rain probability indicator\n        rain_color = 'red' if row['rain_probability'] &gt;= 80 else 'orange' if row['rain_probability'] &gt;= 50 else 'gray'\n        rain_indicator = f'&lt;span style=\"color: {rain_color};\"&gt;üî¥ {row[\"rain_probability\"]:.0f}%&lt;/span&gt;' if row['rain_probability'] &gt;= 50 else f'&lt;span style=\"color: {rain_color};\"&gt;üü¢ {row[\"rain_probability\"]:.0f}%&lt;/span&gt;'\n\n        # Today highlighting\n        row_style = 'font-size: 1.2em; font-weight: bold;' if row['is_today'] else ''\n\n        return {\n            'Date': f'&lt;span style=\"{row_style}\"&gt;{date_str}&lt;/span&gt;',\n            'Weather': f'&lt;span style=\"{row_style}\"&gt;{weather_icon}&lt;/span&gt;',\n            'Temperature': f'&lt;span style=\"{row_style}\"&gt;{temp_range}&lt;/span&gt;',\n            'Wind': f'&lt;span style=\"{row_style}\"&gt;üí® {row[\"wind_speed_max\"]:.1f} km/h&lt;/span&gt;',\n            'Rain': rain_indicator,\n            'Air Quality': aq_badge\n        }\n\n    # Apply formatting to all rows\n    formatted_rows = [format_weather_row(row) for _, row in weather_df.iterrows()]\n\n    return pd.DataFrame(formatted_rows)\n\n# Display in Streamlit\nst.markdown(\"### üìä Weather Details\")\nst.dataframe(\n    create_weather_table(weather_df, language),\n    width=1200,\n    hide_index=True,\n    unsafe_allow_html=True\n)\nTable Features: - Weather Icons: Emoji representation for quick visual understanding - Today Highlighting: Larger, bold text for current day - Air Quality Badges: Color-coded PM2.5 indicators - Rain Probability: Visual indicators with Material Design colors - Responsive Layout: Adapts to different screen sizes"
  },
  {
    "objectID": "posts/weather-trend/index.html#deployment-and-production",
    "href": "posts/weather-trend/index.html#deployment-and-production",
    "title": "Weather Forecast App with Streamlit and AI Integration",
    "section": "",
    "text": "For production deployment, configure environment variables:\n# .env file\nmodelscope=your_modelscope_api_key_here\n\n# Additional production settings\n# Consider rate limiting, caching, and monitoring\n\n\n\n# 1. Install Streamlit CLI\npip install streamlit\n\n# 2. Login to Streamlit\nstreamlit login\n\n# 3. Deploy to Streamlit Cloud\nstreamlit run app.py  # Test locally first\n# Then deploy through cloud.streamlit.io or using CLI\n\n\n\nFROM python:3.9-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY . .\n\nEXPOSE 8501\n\nCMD [\"streamlit\", \"run\", \"app.py\", \"--server.address\", \"0.0.0.0\"]"
  },
  {
    "objectID": "posts/weather-trend/index.html#performance-optimization",
    "href": "posts/weather-trend/index.html#performance-optimization",
    "title": "Weather Forecast App with Streamlit and AI Integration",
    "section": "",
    "text": "@st.cache_data(ttl=3600)  # Cache for 1 hour\ndef get_weather_data_cached(lat, lon):\n    \"\"\"Cached weather data fetching\"\"\"\n    return get_weather_data(lat, lon)\n\n@st.cache_resource\ndef get_ai_client():\n    \"\"\"Cached AI client initialization\"\"\"\n    return init_ai_client()\n\n# Cache map generation\n@st.cache_data(ttl=3600)\ndef create_map_cached(lat, lon):\n    \"\"\"Cached map creation\"\"\"\n    return create_interactive_map(lat, lon)\n\n\n\ndef robust_api_call(func, *args, max_retries=3, **kwargs):\n    \"\"\"Robust API calling with retry logic\"\"\"\n    for attempt in range(max_retries):\n        try:\n            return func(*args, **kwargs)\n        except requests.exceptions.Timeout:\n            if attempt == max_retries - 1:\n                st.error(\"Weather service temporarily unavailable\")\n                return None\n            time.sleep(2 ** attempt)  # Exponential backoff\n        except requests.exceptions.RequestException as e:\n            st.error(f\"API error: {e}\")\n            return None"
  },
  {
    "objectID": "posts/weather-trend/index.html#best-practices-and-lessons-learned",
    "href": "posts/weather-trend/index.html#best-practices-and-lessons-learned",
    "title": "Weather Forecast App with Streamlit and AI Integration",
    "section": "",
    "text": "Modular Architecture: Separate concerns (API, UI, AI, Visualization)\nError Resilience: Comprehensive error handling and fallbacks\nUser Experience: Fast loading with caching and progress indicators\nInternationalization: Plan for multilingual support from the start\nAPI Management: Rate limiting and request optimization\nResponsive Design: Test across different devices and screen sizes\nSecurity: Environment variables for sensitive data\n\n\n\n\n\nData Caching: 1-hour TTL for weather data\nLazy Loading: Load components only when needed\nAsync Operations: Non-blocking API calls where possible\nOptimization: Minimize re-renders and state updates"
  },
  {
    "objectID": "posts/weather-trend/index.html#future-enhancements",
    "href": "posts/weather-trend/index.html#future-enhancements",
    "title": "Weather Forecast App with Streamlit and AI Integration",
    "section": "",
    "text": "Extended AI Capabilities:\n\nMulti-day activity planning\nPersonalized recommendations based on user preferences\nIntegration with calendar applications\n\nAdvanced Visualizations:\n\nWind direction and speed maps\nPrecipitation intensity charts\nHistorical weather comparisons\n\nData Sources:\n\nMultiple weather provider integration\nReal-time radar integration\nWeather alert systems\n\nUser Features:\n\nSaved locations and favorites\nWeather notifications\nHistorical data analysis\nExport functionality\n\nTechnical Enhancements:\n\nWebSocket real-time updates\nProgressive Web App (PWA) features\nOffline functionality"
  },
  {
    "objectID": "posts/weather-trend/index.html#conclusion",
    "href": "posts/weather-trend/index.html#conclusion",
    "title": "Weather Forecast App with Streamlit and AI Integration",
    "section": "",
    "text": "This weather forecast application demonstrates how modern web development technologies can be combined to create a comprehensive, intelligent weather service. The integration of AI-powered recommendations elevates it from a simple data display tool to a practical weather assistant that helps users make informed decisions about their daily activities.\nThe project showcases: - Modern Web Development: Streamlit for rapid prototyping - Data Visualization: Professional charts and interactive maps - AI Integration: Practical use of language models for data analysis - Internationalization: Complete bilingual support - Production Readiness: Error handling, caching, and optimization\nWhether you‚Äôre building weather applications, data dashboards, or AI-powered tools, this project provides an excellent foundation for creating sophisticated, user-friendly applications.\nLive Demo: https://weather-trend.streamlit.app/ Technology Stack: Streamlit, Altair, Folium, ModelScope AI, Open-Meteo API Source Code: Available in the weather_trend directory\n\nReady to build your own weather app? Check out the complete source code and start experimenting with these advanced features today!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "CV / ÁÆÄÂéÜ",
    "section": "",
    "text": "EnglishCareer ObjectiveEmployment HistoryEducation BackgroundTechnical SkillsLanguagesHonors and Awards‰∏≠ÊñáËÅå‰∏öÁõÆÊ†áÂ∑•‰ΩúÁªèÂéÜÊïôËÇ≤ËÉåÊôØ‰∏ì‰∏öÊäÄËÉΩËØ≠Ë®ÄËÉΩÂäõËç£Ë™âÂ•ñÈ°π\n\n\n\nTony Jinchao Duan\nTelephone: 13609618820\nEmail: jcflyingco@outlook.com\n\n\n\nData-driven Strategy & Analytics professional with a proven track record at eBay, EY, and HSBC. Expert in transforming complex datasets into actionable business intelligence and create predictive models to achieve business goal. Specializing in AI-driven Analytic skills and interactive data tools. Seeking to leverage deep domain expertise in data operations and modern AI engineering to drive scalable business growth.\n\n\n\neBay | Business Management | Analytics Specialist (2018-2021) / Analytics Manager (2021-2023)\nStrategic Operations: Managed shipping performance for the Greater China seller network, ensuring alignment with global logistics standards.\nBusiness Intelligence: Designed and deployed comprehensive seller dashboards to monitor real-time performance, significantly reducing shipping delays by identifying supply chain bottlenecks.\nPolicy Development: Authored and implemented regional seller policies that balanced marketplace integrity with sustainable seller growth.\n\n\nErnst & Young | Performance Improvement Consulting | Senior Analytics Consultant (2014-2017)\nBanking Sector: Standardized reporting frameworks for a leading Chinese commercial bank, enhancing data transparency for executive stakeholders. Developed Customer Value Forecast and Segmentation models, enabling targeted CRM strategies and increasing high-value client retention.\nInsurance Sector: Designed a customer product-mix recommendation engine for a top-tier insurance provider. Developed anti-fraud modeling systems for one of the largest life insurance companies in China.\n\n\nHSBC | Consumer Credit Risk | Decision Analytics Officer (2012‚Äì2013)\nDeveloped analytical solutions to manage credit risk across the Asia-Pacific region. Built credit scorecards and optimized strategies for diverse portfolios, including credit cards and home loans, for one of the largest international banks in the region.\n\n\n\nMacquarie University | Sydney, Australia\nBachelor of Commerce (2009 - 2012)\nMajor in Decision Science | GPA: 3.1/4.0\n\n\n\n\n\n\n\n\n\nCategory\nTechnologies\n\n\n\n\nAI/ML\nAgentic Workflows, RAG, LLM Integration, YOLO\n\n\nData Science\nPython (Pandas, Plotly, Scikit-learn), R (Tidyverse, GGplot2, Tidymodels)\n\n\nData Engineering\nSQL (Advanced Querying & Schema Design), Streamlit, Shiny, Quarto\n\n\nMicrosoft Tools\nExcel (VBA/Modeling), PowerPoint, Word\n\n\n\n\n\nEnglish (Professional Proficiency), Mandarin (Native), Cantonese (Native)\n\n\nEY ExCEED Award (2014)\nThe Ernst & Young ExCEED Award is for extra effort, exceeding expectations and recognizing those who have gone that extra mile to serve their clients.\n\n\n\nÊÆµÊôãÊΩÆ Tony Duan\nÁîµËØù: 13609618820\nÈÇÆÁÆ±: jcflyingco@outlook.com\n\n\n\nËµÑÊ∑±Êï∞ÊçÆÊàòÁï•‰∏éÂàÜÊûê‰∏ìÂÆ∂ÔºåÊã•Êúâ eBay„ÄÅÂÆâÊ∞∏ (EY) ÂèäÊ±á‰∏∞Èì∂Ë°å (HSBC) ÁöÑÂ§öÂÖÉÂåñÂÆûÊàòÁªèÈ™å„ÄÇÊìÖÈïøÂ∞ÜÂ§çÊùÇÊï∞ÊçÆÈõÜËΩ¨Âåñ‰∏∫ÂèØËêΩÂú∞ÁöÑ‰∏öÂä°Ê¥ûËßÅÔºåÂπ∂ÈÄöËøáÊûÑÂª∫È¢ÑÊµãÊ®°ÂûãÈ©±Âä®‰∏öÂä°ÁõÆÊ†áËææÊàê„ÄÇÁ≤æÈÄö AI È©±Âä®ÁöÑÂàÜÊûêÊäÄÊúØÂèä‰∫§‰∫íÂºèÊï∞ÊçÆÂ∑•ÂÖ∑ÔºåËá¥Âäõ‰∫éÂà©Áî®Âú®Êï∞ÊçÆËøêËê•ÂíåÁé∞‰ª£AIÂ∑•Á®ãÈ¢ÜÂüüÁöÑÊ∑±ÂéöËÉåÊôØÔºå‰∏∫‰ºÅ‰∏öÂÆûÁé∞ÂèØÊâ©Â±ïÁöÑ‰∏öÂä°Â¢ûÈïø„ÄÇ\n\n\n\neBay | ‰∏öÂä°ÁÆ°ÁêÜÈÉ® ÂàÜÊûê‰∏ìÂÆ∂ (2018-2021) / ÂàÜÊûêÁªèÁêÜ (2021-2023)\nÊàòÁï•ËøêËê•Ôºö ÁªüÁ≠πÂ§ß‰∏≠ÂçéÂå∫ÂçñÂÆ∂ÁöÑÁâ©ÊµÅË°®Áé∞ÁÆ°ÁêÜÔºåÁ°Æ‰øùÂÖ∂Á¨¶ÂêàÂÖ®ÁêÉÁâ©ÊµÅÊó∂Êïà‰∏éÂêàËßÑÊ†áÂáÜ„ÄÇ\nÂïÜ‰∏öÊô∫ËÉΩ (BI)Ôºö ËÆæËÆ°Âπ∂ÈÉ®ÁΩ≤ÂÖ®Áª¥Â∫¶ÂçñÂÆ∂ÁúãÊùøÔºåÂÆûÁé∞ÂÆûÊó∂‰∏öÁª©ÁõëÊéßÔºõÈÄöËøáÁ≤æÂáÜËØÜÂà´‰æõÂ∫îÈìæÁì∂È¢àÔºåÊòæËëóÈôç‰Ωé‰∫ÜÁâ©ÊµÅÂª∂ËøüÁéá„ÄÇ\nÊîøÁ≠ñÂà∂ÂÆöÔºö Ë¥üË¥£Â§ß‰∏≠ÂçéÂå∫ÂçñÂÆ∂ÊîøÁ≠ñÁöÑËµ∑Ëçâ‰∏éÊâßË°åÔºåÂú®Áª¥Êä§Âπ≥Âè∞ÁîüÊÄÅÂÅ•Â∫∑Â∫¶‰∏é‰øùÈöúÂçñÂÆ∂ÂèØÊåÅÁª≠Â¢ûÈïø‰πãÈó¥ÂèñÂæóÊàòÁï•Âπ≥Ë°°„ÄÇ\n\n\nÂÆâÊ∞∏ (EY) | ‰∏öÁª©ÊîπËøõÂí®ËØ¢ÈÉ® È´òÁ∫ßÊï∞ÊçÆÂàÜÊûêÈ°æÈóÆ (2014-2017)\nÈì∂Ë°å‰∏öÂä°Ôºö ‰∏∫ÂõΩÂÜÖÈ¢ÜÂÖàÂïÜ‰∏öÈì∂Ë°åÊûÑÂª∫Ê†áÂáÜÂåñÊä•Ë°®Ê°ÜÊû∂ÔºåÊèêÂçáÁÆ°ÁêÜÂ±ÇÂÜ≥Á≠ñÁöÑÊï∞ÊçÆÈÄèÊòéÂ∫¶ÔºõÂºÄÂèëÂÆ¢Êà∑‰ª∑ÂÄºÈ¢ÑÊµãÂèäÂàÜÁæ§Ê®°ÂûãÔºåËµãËÉΩÁ≤æÂáÜ CRM Á≠ñÁï•ÔºåÊèêÂçáÈ´ò‰ª∑ÂÄºÂÆ¢Êà∑ÁïôÂ≠òÁéá„ÄÇ\n‰øùÈô©‰∏öÂä°Ôºö ‰∏∫Â§¥ÈÉ®‰øùÈô©ÂÖ¨Âè∏ËÆæËÆ°‰∫ßÂìÅÁªÑÂêàÊé®ËçêÂºïÊìéÔºõ‰∏∫ÂõΩÂÜÖÂ§ßÂûãÂØøÈô©ÂÖ¨Âè∏Á†îÂèëÂπ∂ÈÉ®ÁΩ≤ÂèçÊ¨∫ËØàÂª∫Ê®°Á≥ªÁªü„ÄÇ\n\n\nÊ±á‰∏∞Èì∂Ë°å (HSBC) | È£éÈô©ÈÉ® ÂÜ≥Á≠ñÂàÜÊûêÂ∏à (2012-2013)\nË¥üË¥£‰∫öÂ§™Âú∞Âå∫‰ø°Áî®È£éÈô©ÁÆ°ÁêÜÁöÑÂàÜÊûêËß£ÂÜ≥ÊñπÊ°à„ÄÇ‰∏∫ËØ•Âú∞Âå∫ÊúÄÂÖ∑ËßÑÊ®°ÁöÑÂõΩÈôÖÈì∂Ë°åÂºÄÂèë‰ø°Áî®ËØÑÂàÜÂç°ÔºåÂπ∂ÈíàÂØπ‰ø°Áî®Âç°ÂèäÊàøË¥∑Á≠âÂ§öÂÖÉËµÑ‰∫ßÁªÑÂêà‰ºòÂåñÈ£éÈô©Á≠ñÁï•„ÄÇ\n\n\n\nÈ∫¶ËÄÉÁëûÂ§ßÂ≠¶ (Macquarie University) | ÊÇâÂ∞ºÔºåÊæ≥Â§ßÂà©‰∫ö\nÂïÜÂ≠¶Â≠¶Â£´ (2009 - 2012)\n‰∏ì‰∏öÔºöÂÜ≥Á≠ñÁßëÂ≠¶ (Decision Science) | Áª©ÁÇπÔºö3.1 / 4.0\n\n\n\n\n\n\n\n\n\nÁ±ªÂà´\nÊäÄÊúØÊ†à\n\n\n\n\nAI/Êú∫Âô®Â≠¶‰π†\nAgentic Workflows (Êô∫ËÉΩ‰ΩìÂ∑•‰ΩúÊµÅ), RAG (Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê), LLM ÈõÜÊàêÂ∫îÁî®, YOLO ËÆ°ÁÆóÊú∫ËßÜËßâ\n\n\nÊï∞ÊçÆÁßëÂ≠¶\nPython (Pandas, Plotly, Scikit-learn), R (Tidyverse, GGplot2, Tidymodels)\n\n\nÊï∞ÊçÆÂ∑•Á®ã\nSQL (È´òÁ∫ßÊü•ËØ¢‰∏éÊû∂ÊûÑËÆæËÆ°), Streamlit (Web Â∫îÁî®ÂºÄÂèë), Shiny, Quarto\n\n\nÂäûÂÖ¨Â∑•ÂÖ∑\nExcel (VBA/Âª∫Ê®°), PowerPoint, Word\n\n\n\n\n\nËã±ËØ≠Ôºö‰∏ì‰∏öÊµÅÂà© | ÊôÆÈÄöËØù/Á≤§ËØ≠ÔºöÊØçËØ≠\n\n\nÂÆâÊ∞∏ ExCEED ‰ºòÁßÄÂëòÂ∑•Â•ñ (2014)\nÊó®Âú®Ë°®ÂΩ∞Âú®ÂÆ¢Êà∑ÊúçÂä°‰∏≠‰ªòÂá∫È¢ùÂ§ñÂä™Âäõ„ÄÅË°®Áé∞ËøúË∂ÖÈ¢ÑÊúüÂπ∂ÂÅöÂá∫ÂçìË∂äË¥°ÁåÆÁöÑÂëòÂ∑•„ÄÇ"
  },
  {
    "objectID": "cv.html#tony-jinchao-duan",
    "href": "cv.html#tony-jinchao-duan",
    "title": "CV / ÁÆÄÂéÜ",
    "section": "Tony Jinchao Duan",
    "text": "Tony Jinchao Duan\nTelephone: 13609618820\nEmail: jcflyingco@outlook.com"
  },
  {
    "objectID": "cv.html#career-objective",
    "href": "cv.html#career-objective",
    "title": "CV / ÁÆÄÂéÜ",
    "section": "Career Objective",
    "text": "Career Objective\nData-driven Strategy & Analytics professional with a proven track record at eBay, EY, and HSBC. Expert in transforming complex datasets into actionable business intelligence and create predictive models to achieve business goal. Specializing in AI-driven Analytic skills and interactive data tools. Seeking to leverage deep domain expertise in data operations and modern AI engineering to drive scalable business growth."
  },
  {
    "objectID": "cv.html#employment-history",
    "href": "cv.html#employment-history",
    "title": "CV / ÁÆÄÂéÜ",
    "section": "Employment History",
    "text": "Employment History\n\neBay | Business Management | Analytics Specialist (2018-2021) / Analytics Manager (2021-2023)\nStrategic Operations: Managed shipping performance for the Greater China seller network, ensuring alignment with global logistics standards.\nBusiness Intelligence: Designed and deployed comprehensive seller dashboards to monitor real-time performance, significantly reducing shipping delays by identifying supply chain bottlenecks.\nPolicy Development: Authored and implemented regional seller policies that balanced marketplace integrity with sustainable seller growth.\n\n\nErnst & Young | Performance Improvement Consulting | Senior Analytics Consultant (2014-2017)\nBanking Sector: Standardized reporting frameworks for a leading Chinese commercial bank, enhancing data transparency for executive stakeholders. Developed Customer Value Forecast and Segmentation models, enabling targeted CRM strategies and increasing high-value client retention.\nInsurance Sector: Designed a customer product-mix recommendation engine for a top-tier insurance provider. Developed anti-fraud modeling systems for one of the largest life insurance companies in China.\n\n\nHSBC | Consumer Credit Risk | Decision Analytics Officer (2012‚Äì2013)\nDeveloped analytical solutions to manage credit risk across the Asia-Pacific region. Built credit scorecards and optimized strategies for diverse portfolios, including credit cards and home loans, for one of the largest international banks in the region."
  },
  {
    "objectID": "cv.html#education-background",
    "href": "cv.html#education-background",
    "title": "CV / ÁÆÄÂéÜ",
    "section": "Education Background",
    "text": "Education Background\nMacquarie University | Sydney, Australia\nBachelor of Commerce (2009 - 2012)\nMajor in Decision Science | GPA: 3.1/4.0"
  },
  {
    "objectID": "cv.html#technical-skills",
    "href": "cv.html#technical-skills",
    "title": "CV / ÁÆÄÂéÜ",
    "section": "Technical Skills",
    "text": "Technical Skills\n\n\n\n\n\n\n\nCategory\nTechnologies\n\n\n\n\nAI/ML\nAgentic Workflows, RAG, LLM Integration, YOLO\n\n\nData Science\nPython (Pandas, Plotly, Scikit-learn), R (Tidyverse, GGplot2, Tidymodels)\n\n\nData Engineering\nSQL (Advanced Querying & Schema Design), Streamlit, Shiny, Quarto\n\n\nMicrosoft Tools\nExcel (VBA/Modeling), PowerPoint, Word"
  },
  {
    "objectID": "cv.html#languages",
    "href": "cv.html#languages",
    "title": "CV / ÁÆÄÂéÜ",
    "section": "Languages",
    "text": "Languages\nEnglish (Professional Proficiency), Mandarin (Native), Cantonese (Native)"
  },
  {
    "objectID": "cv.html#honors-and-awards",
    "href": "cv.html#honors-and-awards",
    "title": "CV / ÁÆÄÂéÜ",
    "section": "Honors and Awards",
    "text": "Honors and Awards\nEY ExCEED Award (2014)\nThe Ernst & Young ExCEED Award is for extra effort, exceeding expectations and recognizing those who have gone that extra mile to serve their clients."
  },
  {
    "objectID": "cv.html#ÊÆµÊôãÊΩÆ-tony-duan",
    "href": "cv.html#ÊÆµÊôãÊΩÆ-tony-duan",
    "title": "CV / ÁÆÄÂéÜ",
    "section": "ÊÆµÊôãÊΩÆ Tony Duan",
    "text": "ÊÆµÊôãÊΩÆ Tony Duan\nÁîµËØù: 13609618820\nÈÇÆÁÆ±: jcflyingco@outlook.com"
  },
  {
    "objectID": "cv.html#ËÅå‰∏öÁõÆÊ†á",
    "href": "cv.html#ËÅå‰∏öÁõÆÊ†á",
    "title": "CV / ÁÆÄÂéÜ",
    "section": "ËÅå‰∏öÁõÆÊ†á",
    "text": "ËÅå‰∏öÁõÆÊ†á\nËµÑÊ∑±Êï∞ÊçÆÊàòÁï•‰∏éÂàÜÊûê‰∏ìÂÆ∂ÔºåÊã•Êúâ eBay„ÄÅÂÆâÊ∞∏ (EY) ÂèäÊ±á‰∏∞Èì∂Ë°å (HSBC) ÁöÑÂ§öÂÖÉÂåñÂÆûÊàòÁªèÈ™å„ÄÇÊìÖÈïøÂ∞ÜÂ§çÊùÇÊï∞ÊçÆÈõÜËΩ¨Âåñ‰∏∫ÂèØËêΩÂú∞ÁöÑ‰∏öÂä°Ê¥ûËßÅÔºåÂπ∂ÈÄöËøáÊûÑÂª∫È¢ÑÊµãÊ®°ÂûãÈ©±Âä®‰∏öÂä°ÁõÆÊ†áËææÊàê„ÄÇÁ≤æÈÄö AI È©±Âä®ÁöÑÂàÜÊûêÊäÄÊúØÂèä‰∫§‰∫íÂºèÊï∞ÊçÆÂ∑•ÂÖ∑ÔºåËá¥Âäõ‰∫éÂà©Áî®Âú®Êï∞ÊçÆËøêËê•ÂíåÁé∞‰ª£AIÂ∑•Á®ãÈ¢ÜÂüüÁöÑÊ∑±ÂéöËÉåÊôØÔºå‰∏∫‰ºÅ‰∏öÂÆûÁé∞ÂèØÊâ©Â±ïÁöÑ‰∏öÂä°Â¢ûÈïø„ÄÇ"
  },
  {
    "objectID": "cv.html#Â∑•‰ΩúÁªèÂéÜ",
    "href": "cv.html#Â∑•‰ΩúÁªèÂéÜ",
    "title": "CV / ÁÆÄÂéÜ",
    "section": "Â∑•‰ΩúÁªèÂéÜ",
    "text": "Â∑•‰ΩúÁªèÂéÜ\n\neBay | ‰∏öÂä°ÁÆ°ÁêÜÈÉ® ÂàÜÊûê‰∏ìÂÆ∂ (2018-2021) / ÂàÜÊûêÁªèÁêÜ (2021-2023)\nÊàòÁï•ËøêËê•Ôºö ÁªüÁ≠πÂ§ß‰∏≠ÂçéÂå∫ÂçñÂÆ∂ÁöÑÁâ©ÊµÅË°®Áé∞ÁÆ°ÁêÜÔºåÁ°Æ‰øùÂÖ∂Á¨¶ÂêàÂÖ®ÁêÉÁâ©ÊµÅÊó∂Êïà‰∏éÂêàËßÑÊ†áÂáÜ„ÄÇ\nÂïÜ‰∏öÊô∫ËÉΩ (BI)Ôºö ËÆæËÆ°Âπ∂ÈÉ®ÁΩ≤ÂÖ®Áª¥Â∫¶ÂçñÂÆ∂ÁúãÊùøÔºåÂÆûÁé∞ÂÆûÊó∂‰∏öÁª©ÁõëÊéßÔºõÈÄöËøáÁ≤æÂáÜËØÜÂà´‰æõÂ∫îÈìæÁì∂È¢àÔºåÊòæËëóÈôç‰Ωé‰∫ÜÁâ©ÊµÅÂª∂ËøüÁéá„ÄÇ\nÊîøÁ≠ñÂà∂ÂÆöÔºö Ë¥üË¥£Â§ß‰∏≠ÂçéÂå∫ÂçñÂÆ∂ÊîøÁ≠ñÁöÑËµ∑Ëçâ‰∏éÊâßË°åÔºåÂú®Áª¥Êä§Âπ≥Âè∞ÁîüÊÄÅÂÅ•Â∫∑Â∫¶‰∏é‰øùÈöúÂçñÂÆ∂ÂèØÊåÅÁª≠Â¢ûÈïø‰πãÈó¥ÂèñÂæóÊàòÁï•Âπ≥Ë°°„ÄÇ\n\n\nÂÆâÊ∞∏ (EY) | ‰∏öÁª©ÊîπËøõÂí®ËØ¢ÈÉ® È´òÁ∫ßÊï∞ÊçÆÂàÜÊûêÈ°æÈóÆ (2014-2017)\nÈì∂Ë°å‰∏öÂä°Ôºö ‰∏∫ÂõΩÂÜÖÈ¢ÜÂÖàÂïÜ‰∏öÈì∂Ë°åÊûÑÂª∫Ê†áÂáÜÂåñÊä•Ë°®Ê°ÜÊû∂ÔºåÊèêÂçáÁÆ°ÁêÜÂ±ÇÂÜ≥Á≠ñÁöÑÊï∞ÊçÆÈÄèÊòéÂ∫¶ÔºõÂºÄÂèëÂÆ¢Êà∑‰ª∑ÂÄºÈ¢ÑÊµãÂèäÂàÜÁæ§Ê®°ÂûãÔºåËµãËÉΩÁ≤æÂáÜ CRM Á≠ñÁï•ÔºåÊèêÂçáÈ´ò‰ª∑ÂÄºÂÆ¢Êà∑ÁïôÂ≠òÁéá„ÄÇ\n‰øùÈô©‰∏öÂä°Ôºö ‰∏∫Â§¥ÈÉ®‰øùÈô©ÂÖ¨Âè∏ËÆæËÆ°‰∫ßÂìÅÁªÑÂêàÊé®ËçêÂºïÊìéÔºõ‰∏∫ÂõΩÂÜÖÂ§ßÂûãÂØøÈô©ÂÖ¨Âè∏Á†îÂèëÂπ∂ÈÉ®ÁΩ≤ÂèçÊ¨∫ËØàÂª∫Ê®°Á≥ªÁªü„ÄÇ\n\n\nÊ±á‰∏∞Èì∂Ë°å (HSBC) | È£éÈô©ÈÉ® ÂÜ≥Á≠ñÂàÜÊûêÂ∏à (2012-2013)\nË¥üË¥£‰∫öÂ§™Âú∞Âå∫‰ø°Áî®È£éÈô©ÁÆ°ÁêÜÁöÑÂàÜÊûêËß£ÂÜ≥ÊñπÊ°à„ÄÇ‰∏∫ËØ•Âú∞Âå∫ÊúÄÂÖ∑ËßÑÊ®°ÁöÑÂõΩÈôÖÈì∂Ë°åÂºÄÂèë‰ø°Áî®ËØÑÂàÜÂç°ÔºåÂπ∂ÈíàÂØπ‰ø°Áî®Âç°ÂèäÊàøË¥∑Á≠âÂ§öÂÖÉËµÑ‰∫ßÁªÑÂêà‰ºòÂåñÈ£éÈô©Á≠ñÁï•„ÄÇ"
  },
  {
    "objectID": "cv.html#ÊïôËÇ≤ËÉåÊôØ",
    "href": "cv.html#ÊïôËÇ≤ËÉåÊôØ",
    "title": "CV / ÁÆÄÂéÜ",
    "section": "ÊïôËÇ≤ËÉåÊôØ",
    "text": "ÊïôËÇ≤ËÉåÊôØ\nÈ∫¶ËÄÉÁëûÂ§ßÂ≠¶ (Macquarie University) | ÊÇâÂ∞ºÔºåÊæ≥Â§ßÂà©‰∫ö\nÂïÜÂ≠¶Â≠¶Â£´ (2009 - 2012)\n‰∏ì‰∏öÔºöÂÜ≥Á≠ñÁßëÂ≠¶ (Decision Science) | Áª©ÁÇπÔºö3.1 / 4.0"
  },
  {
    "objectID": "cv.html#‰∏ì‰∏öÊäÄËÉΩ",
    "href": "cv.html#‰∏ì‰∏öÊäÄËÉΩ",
    "title": "CV / ÁÆÄÂéÜ",
    "section": "‰∏ì‰∏öÊäÄËÉΩ",
    "text": "‰∏ì‰∏öÊäÄËÉΩ\n\n\n\n\n\n\n\nÁ±ªÂà´\nÊäÄÊúØÊ†à\n\n\n\n\nAI/Êú∫Âô®Â≠¶‰π†\nAgentic Workflows (Êô∫ËÉΩ‰ΩìÂ∑•‰ΩúÊµÅ), RAG (Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê), LLM ÈõÜÊàêÂ∫îÁî®, YOLO ËÆ°ÁÆóÊú∫ËßÜËßâ\n\n\nÊï∞ÊçÆÁßëÂ≠¶\nPython (Pandas, Plotly, Scikit-learn), R (Tidyverse, GGplot2, Tidymodels)\n\n\nÊï∞ÊçÆÂ∑•Á®ã\nSQL (È´òÁ∫ßÊü•ËØ¢‰∏éÊû∂ÊûÑËÆæËÆ°), Streamlit (Web Â∫îÁî®ÂºÄÂèë), Shiny, Quarto\n\n\nÂäûÂÖ¨Â∑•ÂÖ∑\nExcel (VBA/Âª∫Ê®°), PowerPoint, Word"
  },
  {
    "objectID": "cv.html#ËØ≠Ë®ÄËÉΩÂäõ",
    "href": "cv.html#ËØ≠Ë®ÄËÉΩÂäõ",
    "title": "CV / ÁÆÄÂéÜ",
    "section": "ËØ≠Ë®ÄËÉΩÂäõ",
    "text": "ËØ≠Ë®ÄËÉΩÂäõ\nËã±ËØ≠Ôºö‰∏ì‰∏öÊµÅÂà© | ÊôÆÈÄöËØù/Á≤§ËØ≠ÔºöÊØçËØ≠"
  },
  {
    "objectID": "cv.html#Ëç£Ë™âÂ•ñÈ°π",
    "href": "cv.html#Ëç£Ë™âÂ•ñÈ°π",
    "title": "CV / ÁÆÄÂéÜ",
    "section": "Ëç£Ë™âÂ•ñÈ°π",
    "text": "Ëç£Ë™âÂ•ñÈ°π\nÂÆâÊ∞∏ ExCEED ‰ºòÁßÄÂëòÂ∑•Â•ñ (2014)\nÊó®Âú®Ë°®ÂΩ∞Âú®ÂÆ¢Êà∑ÊúçÂä°‰∏≠‰ªòÂá∫È¢ùÂ§ñÂä™Âäõ„ÄÅË°®Áé∞ËøúË∂ÖÈ¢ÑÊúüÂπ∂ÂÅöÂá∫ÂçìË∂äË¥°ÁåÆÁöÑÂëòÂ∑•„ÄÇ"
  }
]